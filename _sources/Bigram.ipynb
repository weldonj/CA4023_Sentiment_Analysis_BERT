{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Implementation\n",
    "\n",
    "To use Bigrams instead of Unigrams I had to make some changes to how the vocabulary was built. In the cell below it can be seen that the tokens are now appended as pairs of strings instead of single strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== pos ==\n",
      "doc sentences start of first sentence\n",
      "  0      25   films adapted|adapted from|from comic|comic books|books have|have had\n",
      "  1      39   every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "  2      19   you've got|got mail|mail works|works alot|alot better|better than\n",
      "  3      42   \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "  4      25   moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "== neg ==\n",
      "doc sentences start of first sentence\n",
      "  0      35   plot :|: two|two teen|teen couples|couples go|go to|to a|a church\n",
      "  1      13   the happy|happy bastard's|bastard's quick|quick movie|movie review\n",
      "  2      23   it is|is movies|movies like|like these|these that|that make|make a\n",
      "  3      19   \" quest|quest for|for camelot|camelot \"|\" is|is warner|warner bros\n",
      "  4      37   synopsis :|: a|a mentally|mentally unstable|unstable man|man undergoing\n"
     ]
    }
   ],
   "source": [
    "# test \"get_documents()\"\n",
    "\n",
    "def get_document_preview(document, max_length = 72):\n",
    "    s = []\n",
    "    count = 0\n",
    "    reached_limit = False\n",
    "    for sentence in document:\n",
    "        i = 0\n",
    "        \n",
    "        # This while loop will ensure that we append pairs of strings as our tokens rather than single strings\n",
    "        while (i < len(sentence) - 1):\n",
    "            token = sentence[i] + ' ' + sentence[i+1]\n",
    "            if count + len(token) + len(s) > max_length:\n",
    "                reached_limit = True\n",
    "                break\n",
    "\n",
    "            s.append(token)\n",
    "            count += len(token)\n",
    "            i+=1\n",
    "        if reached_limit:\n",
    "            break\n",
    "    return '|'.join(s)\n",
    "    \n",
    "for label in 'pos neg'.split():\n",
    "    print(f'== {label} ==')\n",
    "    print('doc sentences start of first sentence')\n",
    "    for index, document in enumerate(data_loader.get_documents(\n",
    "        label = label\n",
    "    )):\n",
    "        print('%3d %7d   %s' %(\n",
    "            index, len(document), get_document_preview(document)\n",
    "        ))\n",
    "        if index == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-size te-size (number of documents)\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n"
     ]
    }
   ],
   "source": [
    "# test \"get_xval_splits()\"\n",
    "\n",
    "splits = data_loader.get_xval_splits()\n",
    "\n",
    "print('tr-size te-size (number of documents)')\n",
    "for xval_tr_data, xval_te_data in splits:\n",
    "    print('%7d %7d' %(len(xval_tr_data), len(xval_te_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorInterface:\n",
    "\n",
    "    def train(self, data_with_labels):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this version of the PolarityPredictorWithVocabulary class will now append pairs of strings instead of single strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithVocabulary(PolarityPredictorInterface):\n",
    "    \n",
    "    def train(self, data_with_labels):\n",
    "        self.reset_vocab()\n",
    "        self.add_to_vocab_from_data(data_with_labels)\n",
    "        self.finalise_vocab()\n",
    "        tr_features = self.extract_features(\n",
    "            data_with_labels\n",
    "        )\n",
    "        tr_targets = self.get_targets(data_with_labels)\n",
    "        self.train_model_on_features(tr_features, tr_targets)\n",
    "        \n",
    "    def reset_vocab(self):\n",
    "        self.vocab = set()\n",
    "        \n",
    "    def add_to_vocab_from_data(self, data):\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                i = 0\n",
    "                while (i < len(sentence) - 1):\n",
    "                    token = sentence[i] + ' ' + sentence[i+1]\n",
    "                    self.vocab.add(token)\n",
    "                    i+=1\n",
    "\n",
    "    def finalise_vocab(self):\n",
    "        self.vocab = list(self.vocab)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.token2index = {}\n",
    "        for index, token in enumerate(self.vocab):\n",
    "            self.token2index[token] = index\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_targets(self, data, label2index = None):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "class PolarityPredictorWithBagOfWords_01(PolarityPredictorWithVocabulary):\n",
    "    \n",
    "    def __init__(self, clip_counts = True):\n",
    "        self.clip_counts = clip_counts\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        # create numpy array of required size\n",
    "        columns = len(self.vocab)\n",
    "        rows = len(data)\n",
    "        features = numpy.zeros((rows, columns), dtype=numpy.int32)        \n",
    "        # populate feature matrix\n",
    "        for row, item in enumerate(data):\n",
    "            document, _ = item\n",
    "            for sentence in document:\n",
    "\n",
    "                i = 0\n",
    "                while (i < len(sentence)-1):\n",
    "                    token = sentence[i] + ' ' + sentence[i+1]\n",
    "                    i+=1\n",
    "\n",
    "                    try:\n",
    "                        index = self.token2index[token]\n",
    "                    except KeyError:\n",
    "                        # token not in vocab\n",
    "                        # --> skip this token\n",
    "                        # --> continue with next token\n",
    "                        continue\n",
    "                    if self.clip_counts:\n",
    "                        features[row, index] = 1\n",
    "                    else:\n",
    "                        features[row, index] += 1\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithBagOfWords(PolarityPredictorWithBagOfWords_01):\n",
    " \n",
    "    def get_targets(self, data):\n",
    "        ''' create column vector with target labels\n",
    "        '''\n",
    "        # prepare target vector\n",
    "        targets = numpy.zeros(len(data), dtype=numpy.int8)\n",
    "        index = 0\n",
    "        for _, label in data:\n",
    "            if label == 'pos':\n",
    "                targets[index] = 1\n",
    "            index += 1\n",
    "        return targets\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowNB(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train NB\n",
    "        self.model = MultinomialNB()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first functionality test\n",
    "\n",
    "model = PolarityPredictorBowNB()\n",
    "model.train(splits[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 pos pos films adapted|adapted from|from comic|comic books|books have|have had\n",
      "   1 pos pos every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "   2 pos pos you've got|got mail|mail works|works alot|alot better|better than\n",
      "   3 pos pos \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "   4 pos neg moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "   5 pos pos on june|june 30|30 ,|, 1960|1960 ,|, a|a self-taught|self-taught ,\n",
      "   6 pos pos apparently ,|, director|director tony|tony kaye|kaye had|had a|a major\n",
      "   7 pos pos one of|of my|my colleagues|colleagues was|was surprised|surprised when\n",
      "   8 pos pos after bloody|bloody clashes|clashes and|and independence\n",
      "   9 pos pos the american|american action|action film|film has|has been|been slowly\n",
      "  10 pos pos after watching|watching \"|\" rat|rat race|race \"|\" last|last week|week ,\n",
      "  11 pos pos i've noticed|noticed something|something lately|lately that|that i've\n"
     ]
    }
   ],
   "source": [
    "def print_first_predictions(model, te_data, n = 12):\n",
    "    predictions = model.predict(te_data)\n",
    "    for i in range(n):\n",
    "        document, label = te_data[i]\n",
    "        prediction = predictions[i]\n",
    "        print('%4d %s %s %s' %(\n",
    "            i, label, prediction,\n",
    "            get_document_preview(document),\n",
    "        ))\n",
    "    \n",
    "print_first_predictions(model, splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n",
      "[[78 22]\n",
      " [15 85]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.815\n",
      "Precision --> 0.78\n",
      "Recall --> 0.8387096774193549\n",
      "F1 --> 0.8082901554404146\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.88\n",
      "Precision --> 0.87\n",
      "Recall --> 0.8877551020408163\n",
      "F1 --> 0.8787878787878789\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.85\n",
      "Recall --> 0.8585858585858586\n",
      "F1 --> 0.8542713567839195\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.87\n",
      "Precision --> 0.84\n",
      "Recall --> 0.8936170212765957\n",
      "F1 --> 0.8659793814432989\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.83\n",
      "Precision --> 0.8\n",
      "Recall --> 0.851063829787234\n",
      "F1 --> 0.8247422680412372\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.845\n",
      "Precision --> 0.78\n",
      "Recall --> 0.896551724137931\n",
      "F1 --> 0.8342245989304813\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.865\n",
      "Precision --> 0.82\n",
      "Recall --> 0.9010989010989011\n",
      "F1 --> 0.8586387434554974\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.79\n",
      "Recall --> 0.9080459770114943\n",
      "F1 --> 0.8449197860962566\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.82\n",
      "Recall --> 0.8541666666666666\n",
      "F1 --> 0.836734693877551\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.83\n",
      "Recall --> 0.8736842105263158\n",
      "F1 --> 0.8512820512820513\n",
      "\n",
      "(0.8457870914138587, 0.01900458933856416, 0.8082901554404146, 0.8787878787878789)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, splits, verbose = False):\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    fold = 0\n",
    "    for tr_data, te_data in splits:\n",
    "        if verbose:\n",
    "            print('Evaluating fold %d of %d' %(fold+1, len(splits)))\n",
    "            fold += 1\n",
    "        model.train(tr_data)\n",
    "        _, accuracy, confusion_matrix = model.predict(te_data, get_accuracy = True, get_confusion_matrix = True)\n",
    "        \n",
    "        tp, fp, fn, tn = confusion_matrix[0][0], confusion_matrix[0][1], confusion_matrix[1][0], confusion_matrix[1][1]\n",
    "        prec = tp/(tp + fp)\n",
    "        rec = tp/(tp + fn)\n",
    "        f1 = (2*prec*rec)/(prec+rec)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        f1s.append(f1)\n",
    "        if verbose:\n",
    "            print('Accuracy -->', accuracy)\n",
    "            print('Precision -->', prec)\n",
    "            print('Recall -->', rec)\n",
    "            print('F1 -->', f1)\n",
    "            print()\n",
    "    n = float(len(accuracies))\n",
    "    avg = sum(f1s) / n\n",
    "    mse = sum([(x-avg)**2 for x in accuracies]) / n\n",
    "    return (avg, mse**0.5, min(f1s),\n",
    "            max(f1s))\n",
    "\n",
    "# this takes about 3 minutes\n",
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score of **0.845** was an improvement over the Baseline NB implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowLR(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowLR()\n",
    "model.train(splits[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 pos pos films adapted|adapted from|from comic|comic books|books have|have had\n",
      "   1 pos pos every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "   2 pos neg you've got|got mail|mail works|works alot|alot better|better than\n",
      "   3 pos pos \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "   4 pos neg moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "   5 pos pos on june|june 30|30 ,|, 1960|1960 ,|, a|a self-taught|self-taught ,\n",
      "   6 pos pos apparently ,|, director|director tony|tony kaye|kaye had|had a|a major\n",
      "   7 pos pos one of|of my|my colleagues|colleagues was|was surprised|surprised when\n",
      "   8 pos pos after bloody|bloody clashes|clashes and|and independence\n",
      "   9 pos pos the american|american action|action film|film has|has been|been slowly\n",
      "  10 pos pos after watching|watching \"|\" rat|rat race|race \"|\" last|last week|week ,\n",
      "  11 pos pos i've noticed|noticed something|something lately|lately that|that i've\n"
     ]
    }
   ],
   "source": [
    "print_first_predictions(model, splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "[[87 13]\n",
      " [19 81]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.87\n",
      "Recall --> 0.8207547169811321\n",
      "F1 --> 0.8446601941747572\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.865\n",
      "Precision --> 0.89\n",
      "Recall --> 0.8476190476190476\n",
      "F1 --> 0.8682926829268293\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.81\n",
      "Precision --> 0.91\n",
      "Recall --> 0.7583333333333333\n",
      "F1 --> 0.8272727272727273\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.85\n",
      "Recall --> 0.8333333333333334\n",
      "F1 --> 0.8415841584158417\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.79\n",
      "Precision --> 0.8\n",
      "Recall --> 0.7843137254901961\n",
      "F1 --> 0.792079207920792\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.83\n",
      "Precision --> 0.88\n",
      "Recall --> 0.8\n",
      "F1 --> 0.8380952380952381\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.81\n",
      "Recall --> 0.8617021276595744\n",
      "F1 --> 0.8350515463917526\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.835\n",
      "Precision --> 0.83\n",
      "Recall --> 0.8383838383838383\n",
      "F1 --> 0.8341708542713568\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.89\n",
      "Recall --> 0.8317757009345794\n",
      "F1 --> 0.8599033816425121\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.87\n",
      "Recall --> 0.8446601941747572\n",
      "F1 --> 0.8571428571428571\n",
      "\n",
      "(0.8398252848254664, 0.02141571395018019, 0.792079207920792, 0.8682926829268293)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score of **0.84** was worse than the Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class PolarityPredictorBowDT(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = DecisionTreeClassifier()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowDT()\n",
    "model.train(splits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "[[55 45]\n",
      " [35 65]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.59\n",
      "Precision --> 0.53\n",
      "Recall --> 0.6022727272727273\n",
      "F1 --> 0.5638297872340425\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.56\n",
      "Precision --> 0.47\n",
      "Recall --> 0.573170731707317\n",
      "F1 --> 0.5164835164835165\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.61\n",
      "Precision --> 0.71\n",
      "Recall --> 0.5916666666666667\n",
      "F1 --> 0.6454545454545454\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.61\n",
      "Precision --> 0.57\n",
      "Recall --> 0.6195652173913043\n",
      "F1 --> 0.59375\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.565\n",
      "Precision --> 0.6\n",
      "Recall --> 0.5607476635514018\n",
      "F1 --> 0.5797101449275363\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.57\n",
      "Precision --> 0.59\n",
      "Recall --> 0.5673076923076923\n",
      "F1 --> 0.5784313725490196\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.65\n",
      "Precision --> 0.67\n",
      "Recall --> 0.6442307692307693\n",
      "F1 --> 0.6568627450980393\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.57\n",
      "Precision --> 0.54\n",
      "Recall --> 0.574468085106383\n",
      "F1 --> 0.5567010309278351\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.565\n",
      "Precision --> 0.6\n",
      "Recall --> 0.5607476635514018\n",
      "F1 --> 0.5797101449275363\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.555\n",
      "Precision --> 0.61\n",
      "Recall --> 0.5495495495495496\n",
      "F1 --> 0.5781990521327014\n",
      "\n",
      "(0.5849132339734772, 0.028764922428486328, 0.5164835164835165, 0.6568627450980393)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class PolarityPredictorBowSVM(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = svm.SVC()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowSVM()\n",
    "model.train(splits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n",
      "[[96  4]\n",
      " [50 50]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.73\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6575342465753424\n",
      "F1 --> 0.7804878048780488\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.755\n",
      "Precision --> 0.98\n",
      "Recall --> 0.6758620689655173\n",
      "F1 --> 0.8\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.69\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6233766233766234\n",
      "F1 --> 0.7559055118110236\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.705\n",
      "Precision --> 0.94\n",
      "Recall --> 0.6394557823129252\n",
      "F1 --> 0.7611336032388665\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.69\n",
      "Precision --> 0.94\n",
      "Recall --> 0.6266666666666667\n",
      "F1 --> 0.752\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.73\n",
      "Precision --> 0.93\n",
      "Recall --> 0.6642857142857143\n",
      "F1 --> 0.775\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.74\n",
      "Precision --> 0.95\n",
      "Recall --> 0.6690140845070423\n",
      "F1 --> 0.7851239669421488\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.715\n",
      "Precision --> 0.93\n",
      "Recall --> 0.6503496503496503\n",
      "F1 --> 0.7654320987654321\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.77\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6956521739130435\n",
      "F1 --> 0.8067226890756302\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.73\n",
      "Precision --> 0.95\n",
      "Recall --> 0.6597222222222222\n",
      "F1 --> 0.7786885245901639\n",
      "\n",
      "(0.7760494199301314, 0.05632489551941284, 0.752, 0.8067226890756302)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 Score for SVM of **0.77** was worse than Baseline SVM\n",
    "\n",
    "Once again, implementing Bigrams didn't guarantee an improvment in the performance of any individual algorithm but it did improve some, at the cost of a slower run time.\n",
    "\n",
    "The next step was to examine what a move to Trigrams might do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
