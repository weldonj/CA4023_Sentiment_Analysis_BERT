{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PL04DataLoader_Part_1:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_labelled_dataset(self, fold = 0):\n",
    "        ''' Compile a fold of the data set\n",
    "        '''\n",
    "        dataset = []\n",
    "        for label in ('pos', 'neg'):\n",
    "            for document in self.get_documents(\n",
    "                fold = fold,\n",
    "                label = label,\n",
    "            ):\n",
    "                dataset.append((document, label))\n",
    "        return dataset\n",
    "    \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        ''' Enumerate the raw contents of all data set files.\n",
    "            Args:\n",
    "                data_dir: relative or absolute path to the data set folder\n",
    "                fold: which fold to load (0 to n_folds-1)\n",
    "                label: 'pos' or 'neg' to\n",
    "                    select data with positive or negative sentiment\n",
    "                    polarity\n",
    "            Return:\n",
    "                List of tokenised documents, each a list of sentences\n",
    "                that in turn are lists of tokens\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "class PL04DataLoader(PL04DataLoader_Part_1):\n",
    "    \n",
    "    def get_xval_splits(self):\n",
    "        ''' Split data with labels for cross-validation\n",
    "            returns a list of k pairs (training_data, test_data)\n",
    "            for k cross-validation\n",
    "        '''\n",
    "        # load the folds\n",
    "        folds = []\n",
    "        for i in range(10):\n",
    "            folds.append(self.get_labelled_dataset(\n",
    "                fold = i\n",
    "            ))\n",
    "        # create training-test splits\n",
    "        retval = []\n",
    "        for i in range(10):\n",
    "            test_data = folds[i]\n",
    "            training_data = []\n",
    "            for j in range(9):\n",
    "                ij1 = (i+j+1) % 10\n",
    "                assert ij1 != i\n",
    "                training_data = training_data + folds[ij1]\n",
    "            retval.append((training_data, test_data))\n",
    "        return retval\n",
    "    \n",
    "class PL04DataLoaderFromStream(PL04DataLoader):\n",
    "        \n",
    "    def __init__(self, tgz_stream, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = {}\n",
    "        counter = 0\n",
    "        with tarfile.open(\n",
    "            mode = 'r|gz',\n",
    "            fileobj = tgz_stream\n",
    "        ) as tar_archive:\n",
    "            for tar_member in tar_archive:\n",
    "                if counter == 2000:\n",
    "                    break\n",
    "                path_components = tar_member.name.split('/')\n",
    "                filename = path_components[-1]\n",
    "                if filename.startswith('cv') \\\n",
    "                and filename.endswith('.txt') \\\n",
    "                and '_' in filename:\n",
    "                    label = path_components[-2]\n",
    "                    fold = int(filename[2])\n",
    "                    key = (fold, label)\n",
    "                    if key not in self.data:\n",
    "                        self.data[key] = []\n",
    "                    f = tar_archive.extractfile(tar_member)\n",
    "                    document = [\n",
    "                        line.decode('utf-8').split()\n",
    "                        for line in f.readlines()\n",
    "                    ]\n",
    "                    self.data[key].append(document)\n",
    "                    counter += 1\n",
    "            \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        return self.data[(fold, label)]\n",
    "\n",
    "class PL04DataLoaderFromTGZ(PL04DataLoaderFromStream):\n",
    "    \n",
    "    def __init__(self, data_path, **kwargs):\n",
    "        with open(data_path, 'rb') as tgz_stream:\n",
    "            super().__init__(tgz_stream, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_entries = os.listdir()\n",
    "dir_entries.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = PL04DataLoaderFromTGZ('data.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== pos ==\n",
      "doc sentences start of first sentence\n",
      "  0      25   films|adapted|from|comic|books|have|had|plenty|of|success|,|whether\n",
      "  1      39   every|now|and|then|a|movie|comes|along|from|a|suspect|studio|,|with\n",
      "  2      19   you've|got|mail|works|alot|better|than|it|deserves|to|.|in|order|to|make\n",
      "  3      42   \"|jaws|\"|is|a|rare|film|that|grabs|your|attention|before|it|shows|you|a\n",
      "  4      25   moviemaking|is|a|lot|like|being|the|general|manager|of|an|nfl|team|in\n",
      "== neg ==\n",
      "doc sentences start of first sentence\n",
      "  0      35   plot|:|two|teen|couples|go|to|a|church|party|,|drink|and|then|drive|.\n",
      "  1      13   the|happy|bastard's|quick|movie|review|damn|that|y2k|bug|.|it's|got|a\n",
      "  2      23   it|is|movies|like|these|that|make|a|jaded|movie|viewer|thankful|for|the\n",
      "  3      19   \"|quest|for|camelot|\"|is|warner|bros|.|'|first|feature-length|,\n",
      "  4      37   synopsis|:|a|mentally|unstable|man|undergoing|psychotherapy|saves|a|boy\n"
     ]
    }
   ],
   "source": [
    "# test \"get_documents()\"\n",
    "\n",
    "def get_document_preview(document, max_length = 72):\n",
    "    s = []\n",
    "    count = 0\n",
    "    reached_limit = False\n",
    "    for sentence in document:\n",
    "        for token in sentence:\n",
    "            if count + len(token) + len(s) > max_length:\n",
    "                reached_limit = True\n",
    "                break\n",
    "            s.append(token)\n",
    "            count += len(token)\n",
    "        if reached_limit:\n",
    "            break\n",
    "    return '|'.join(s)\n",
    "    \n",
    "for label in 'pos neg'.split():\n",
    "    print(f'== {label} ==')\n",
    "    print('doc sentences start of first sentence')\n",
    "    for index, document in enumerate(data_loader.get_documents(\n",
    "        label = label\n",
    "    )):\n",
    "        print('%3d %7d   %s' %(\n",
    "            index, len(document), get_document_preview(document)\n",
    "        ))\n",
    "        if index == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-size te-size (number of documents)\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n"
     ]
    }
   ],
   "source": [
    "# test \"get_xval_splits()\"\n",
    "\n",
    "splits = data_loader.get_xval_splits()\n",
    "\n",
    "print('tr-size te-size (number of documents)')\n",
    "for xval_tr_data, xval_te_data in splits:\n",
    "    print('%7d %7d' %(len(xval_tr_data), len(xval_te_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorInterface:\n",
    "\n",
    "    def train(self, data_with_labels):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithVocabulary(PolarityPredictorInterface):\n",
    "    \n",
    "    def train(self, data_with_labels):\n",
    "        self.reset_vocab()\n",
    "        self.add_to_vocab_from_data(data_with_labels)\n",
    "        self.finalise_vocab()\n",
    "        tr_features = self.extract_features(\n",
    "            data_with_labels\n",
    "        )\n",
    "        tr_targets = self.get_targets(data_with_labels)\n",
    "        self.train_model_on_features(tr_features, tr_targets)\n",
    "        \n",
    "    def reset_vocab(self):\n",
    "        self.vocab = set()\n",
    "        \n",
    "    def add_to_vocab_from_data(self, data):\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                for token in sentence:\n",
    "                    self.vocab.add(token)\n",
    "\n",
    "    def finalise_vocab(self):\n",
    "        self.vocab = list(self.vocab)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.token2index = {}\n",
    "        for index, token in enumerate(self.vocab):\n",
    "            self.token2index[token] = index\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_targets(self, data, label2index = None):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "class PolarityPredictorWithBagOfWords_01(PolarityPredictorWithVocabulary):\n",
    "    \n",
    "    def __init__(self, clip_counts = True):\n",
    "        self.clip_counts = clip_counts\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        # create numpy array of required size\n",
    "        columns = len(self.vocab)\n",
    "        rows = len(data)\n",
    "        features = numpy.zeros((rows, columns), dtype=numpy.int32)        \n",
    "        # populate feature matrix\n",
    "        for row, item in enumerate(data):\n",
    "            document, _ = item\n",
    "            for sentence in document:\n",
    "                for token in sentence:\n",
    "                    try:\n",
    "                        index = self.token2index[token]\n",
    "                    except KeyError:\n",
    "                        # token not in vocab\n",
    "                        # --> skip this token\n",
    "                        # --> continue with next token\n",
    "                        continue\n",
    "                    if self.clip_counts:\n",
    "                        features[row, index] = 1\n",
    "                    else:\n",
    "                        features[row, index] += 1\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithBagOfWords(PolarityPredictorWithBagOfWords_01):\n",
    " \n",
    "    def get_targets(self, data):\n",
    "        ''' create column vector with target labels\n",
    "        '''\n",
    "        # prepare target vector\n",
    "        targets = numpy.zeros(len(data), dtype=numpy.int8)\n",
    "        index = 0\n",
    "        for _, label in data:\n",
    "            if label == 'pos':\n",
    "                targets[index] = 1\n",
    "            index += 1\n",
    "        return targets\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "These next few cells set up the baseline Naive Bayes model that we were supplied with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowNB(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train NB\n",
    "        self.model = MultinomialNB()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for i, is_positive in enumerate(y_pred):\n",
    "\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval, y_true, y_pred\n",
    "        else:\n",
    "            return labels, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first functionality test\n",
    "\n",
    "model = PolarityPredictorBowNB()\n",
    "model.train(splits[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true, pred = model.predict(splits[0][1], get_accuracy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = y_true==pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrects_nb = []\n",
    "for i, answer in enumerate(corrects):\n",
    "    if answer == False:\n",
    "        incorrects_nb.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4,\n",
       " 19,\n",
       " 22,\n",
       " 25,\n",
       " 28,\n",
       " 34,\n",
       " 40,\n",
       " 44,\n",
       " 49,\n",
       " 50,\n",
       " 54,\n",
       " 55,\n",
       " 57,\n",
       " 58,\n",
       " 72,\n",
       " 75,\n",
       " 80,\n",
       " 82,\n",
       " 89,\n",
       " 90,\n",
       " 93,\n",
       " 98,\n",
       " 103,\n",
       " 108,\n",
       " 110,\n",
       " 124,\n",
       " 125,\n",
       " 134,\n",
       " 135,\n",
       " 141,\n",
       " 142,\n",
       " 154,\n",
       " 159,\n",
       " 160,\n",
       " 175,\n",
       " 176,\n",
       " 186,\n",
       " 190,\n",
       " 194,\n",
       " 197]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrects_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowLR(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_256_files = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    bert_256_files.append(f'256_BERT/{i}_pred.txt')\n",
    "\n",
    "\n",
    "bert_512_files = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    bert_512_files.append(f'512_BERT/{i}_pred_512.txt')\n",
    "    \n",
    "\n",
    "bert_512_12_files = []\n",
    "    \n",
    "for i in range(1,11):\n",
    "    bert_512_12_files.append(f'512_12_BERT/{i}_pred_512_12.txt')    \n",
    "\n",
    "    \n",
    "bert_256_neg_files = ['256_BERT_NEG/1_pred_negation.txt']\n",
    "\n",
    "    \n",
    "c_names = ['gold','pred','correct','text']\n",
    "\n",
    "df1 = pd.DataFrame(columns=c_names)\n",
    "df2 = pd.DataFrame(columns=c_names)\n",
    "df3 = pd.DataFrame(columns=c_names)\n",
    "df4 = pd.DataFrame(columns=c_names)\n",
    "df5 = pd.DataFrame(columns=c_names)\n",
    "df6 = pd.DataFrame(columns=c_names)\n",
    "df7 = pd.DataFrame(columns=c_names)\n",
    "df8 = pd.DataFrame(columns=c_names)\n",
    "df9 = pd.DataFrame(columns=c_names)\n",
    "df10 = pd.DataFrame(columns=c_names)\n",
    "\n",
    "df1_512 = pd.DataFrame(columns=c_names)\n",
    "df2_512 = pd.DataFrame(columns=c_names)\n",
    "df3_512 = pd.DataFrame(columns=c_names)\n",
    "df4_512 = pd.DataFrame(columns=c_names)\n",
    "df5_512 = pd.DataFrame(columns=c_names)\n",
    "df6_512 = pd.DataFrame(columns=c_names)\n",
    "df7_512 = pd.DataFrame(columns=c_names)\n",
    "df8_512 = pd.DataFrame(columns=c_names)\n",
    "df9_512 = pd.DataFrame(columns=c_names)\n",
    "df10_512 = pd.DataFrame(columns=c_names)\n",
    "\n",
    "df1_512_12 = pd.DataFrame(columns=c_names)\n",
    "df2_512_12 = pd.DataFrame(columns=c_names)\n",
    "df3_512_12 = pd.DataFrame(columns=c_names)\n",
    "df4_512_12 = pd.DataFrame(columns=c_names)\n",
    "df5_512_12 = pd.DataFrame(columns=c_names)\n",
    "df6_512_12 = pd.DataFrame(columns=c_names)\n",
    "df7_512_12 = pd.DataFrame(columns=c_names)\n",
    "df8_512_12 = pd.DataFrame(columns=c_names)\n",
    "df9_512_12 = pd.DataFrame(columns=c_names)\n",
    "df10_512_12 = pd.DataFrame(columns=c_names)\n",
    "\n",
    "df1_neg = pd.DataFrame(columns=c_names)\n",
    "\n",
    "dataframes_256 = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10]\n",
    "\n",
    "dataframes_512 = [df1_512,df2_512,df3_512,df4_512,df5_512,df6_512,df7_512,df8_512,df9_512,df10_512]\n",
    "\n",
    "dataframes_512_12 = [df1_512_12,df2_512_12,df3_512_12,df4_512_12,df5_512_12,df6_512_12,df7_512_12,df8_512_12,df9_512_12,df10_512_12]\n",
    "\n",
    "dataframes_256_neg = [df1_neg]\n",
    "\n",
    "\n",
    "def create_dfs(files, df_list):\n",
    "    j = 0\n",
    "    for dataframe in df_list:\n",
    "\n",
    "        #dataframe = pd.DataFrame(columns=['index','gold','pred','correct','text'])\n",
    "        processed_lines = []\n",
    "\n",
    "        with open(files[j], 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            count = 0\n",
    "            for line in lines[1:]:\n",
    "                tokens = line.split()\n",
    "                line_length = len(tokens)\n",
    "                temp_line = ''\n",
    "\n",
    "                for i in range(4, (line_length)):\n",
    "                    temp_line = temp_line + tokens[i] + ' '\n",
    "\n",
    "                processed_line = [tokens[1],tokens[2],tokens[3], temp_line]\n",
    "                processed_lines.append(processed_line)\n",
    "                dataframe.loc[count] = processed_line\n",
    "                count+=1\n",
    "        j+=1\n",
    "    return(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_256 = create_dfs(bert_256_files, dataframes_256)\n",
    "\n",
    "dataframes_512 = create_dfs(bert_512_files, dataframes_512)\n",
    "\n",
    "dataframes_512_12 = create_dfs(bert_512_12_files, dataframes_512_12)\n",
    "\n",
    "dataframes_256_neg = create_dfs(bert_256_neg_files, dataframes_256_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(dataframe):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    corrects = 0\n",
    "    errors = []\n",
    "    for i in range(0,len(dataframe)):\n",
    "        if dataframe.iat[i,2] == 'yes':\n",
    "            corrects += 1\n",
    "        else:\n",
    "            errors.append(i)\n",
    "        if (dataframe.iat[i,0] == 'pos' and dataframe.iat[i,1] == 'pos'):\n",
    "            true_pos += 1\n",
    "        elif (dataframe.iat[i,0] == 'pos' and dataframe.iat[i,1] == 'neg'):\n",
    "            false_neg += 1\n",
    "        elif (dataframe.iat[i,0] == 'neg' and dataframe.iat[i,1] == 'neg'):\n",
    "            true_neg += 1\n",
    "        elif (dataframe.iat[i,0] == 'neg' and dataframe.iat[i,1] == 'pos'):\n",
    "            false_pos += 1\n",
    "    \n",
    "    accuracy = corrects/len(dataframe)\n",
    "    precision = true_pos/(true_pos + false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    f1_score = 2*((precision*recall)/(precision + recall))\n",
    "    return(accuracy,precision,recall,f1_score,errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averages(df_list):\n",
    "    accuracies = []\n",
    "    precs = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "    errors_list = []\n",
    "    for dataframe in df_list:    \n",
    "        true_pos = 0\n",
    "        true_neg = 0\n",
    "        false_pos = 0\n",
    "        false_neg = 0\n",
    "        corrects = 0\n",
    "        errors = []\n",
    "        for i in range(0,len(dataframe)):\n",
    "            if dataframe.iat[i,2] == 'yes':\n",
    "                corrects += 1\n",
    "            else:\n",
    "                errors.append(i)\n",
    "            if (dataframe.iat[i,0] == 'pos' and dataframe.iat[i,1] == 'pos'):\n",
    "                true_pos += 1\n",
    "            elif (dataframe.iat[i,0] == 'pos' and dataframe.iat[i,1] == 'neg'):\n",
    "                false_neg += 1\n",
    "            elif (dataframe.iat[i,0] == 'neg' and dataframe.iat[i,1] == 'neg'):\n",
    "                true_neg += 1\n",
    "            elif (dataframe.iat[i,0] == 'neg' and dataframe.iat[i,1] == 'pos'):\n",
    "                false_pos += 1\n",
    "\n",
    "        accuracy = corrects/len(dataframe)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        precision = true_pos/(true_pos + false_pos)\n",
    "        precs.append(precision)\n",
    "\n",
    "        recall = true_pos/(true_pos + false_neg)\n",
    "        recs.append(recall)\n",
    "        \n",
    "        f1_score = 2*((precision*recall)/(precision + recall))\n",
    "        f1s.append(f1_score)\n",
    "        \n",
    "        errors_list.append(errors)\n",
    "        \n",
    "    return(sum(accuracies)/len(df_list),sum(precs)/len(df_list),sum(recs)/len(df_list),sum(f1s)/len(df_list), errors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_averages_get_errors(dataframes, errorlist = False):\n",
    "    acc,prec,rec,f1,errors = get_averages(dataframes)\n",
    "    if errorlist == True:\n",
    "        return(errors)\n",
    "    else:\n",
    "        for i, dataframe in enumerate(dataframes):\n",
    "            scores = get_f1(dataframe)\n",
    "            print(f'Cross validation {i+1}')\n",
    "            print(f'The accuracy is {scores[0]*100:.2f}%')\n",
    "            print(f'The precision is {scores[1]*100:.2f}%')\n",
    "            print(f'The recall is {scores[2]*100:.2f}%')\n",
    "            print(f'The F1 score is {scores[3]*100:.2f}%')\n",
    "            print(f'The model got the following rows wrong {scores[4]}\\n')\n",
    "\n",
    "        print(f'The average accuracy is {acc*100:.2f}%')\n",
    "        print(f'The average precision is {prec*100:.2f}%')\n",
    "        print(f'The average recall is {rec*100:.2f}%')\n",
    "        print(f'The average F1 score is {f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_256 = print_averages_get_errors(dataframes_256, True)\n",
    "#error_512 = print_averages_get_errors(dataframes_512, True)\n",
    "error_512_12 = print_averages_get_errors(dataframes_512_12, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 10,\n",
       " 24,\n",
       " 25,\n",
       " 40,\n",
       " 44,\n",
       " 50,\n",
       " 56,\n",
       " 82,\n",
       " 83,\n",
       " 91,\n",
       " 106,\n",
       " 118,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 157,\n",
       " 159,\n",
       " 171,\n",
       " 173]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_512[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 10,\n",
       " 44,\n",
       " 50,\n",
       " 82,\n",
       " 91,\n",
       " 108,\n",
       " 113,\n",
       " 117,\n",
       " 118,\n",
       " 124,\n",
       " 128,\n",
       " 129,\n",
       " 134,\n",
       " 135,\n",
       " 157,\n",
       " 171,\n",
       " 177,\n",
       " 197,\n",
       " 198]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_256[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "44\n",
      "50\n",
      "82\n",
      "91\n",
      "118\n",
      "134\n",
      "135\n",
      "157\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(error_256[0])):\n",
    "    if error_256[0][i] in error_512[0]:\n",
    "        print(error_256[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "24\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(error_512_12[0])):\n",
    "    if error_512_12[0][i] not in error_256[0]:\n",
    "        print(error_512_12[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation 1\n",
      "The accuracy is 90.00%\n",
      "The precision is 87.04%\n",
      "The recall is 94.00%\n",
      "The F1 score is 90.38%\n",
      "The model got the following rows wrong [1, 10, 44, 50, 82, 91, 108, 113, 117, 118, 124, 128, 129, 134, 135, 157, 171, 177, 197, 198]\n",
      "\n",
      "Cross validation 2\n",
      "The accuracy is 87.50%\n",
      "The precision is 85.71%\n",
      "The recall is 90.00%\n",
      "The F1 score is 87.80%\n",
      "The model got the following rows wrong [9, 14, 18, 50, 59, 62, 65, 78, 93, 94, 104, 105, 115, 118, 125, 137, 140, 142, 143, 146, 162, 167, 170, 177, 189]\n",
      "\n",
      "Cross validation 3\n",
      "The accuracy is 95.00%\n",
      "The precision is 93.27%\n",
      "The recall is 97.00%\n",
      "The F1 score is 95.10%\n",
      "The model got the following rows wrong [8, 44, 99, 100, 133, 142, 156, 162, 178, 196]\n",
      "\n",
      "Cross validation 4\n",
      "The accuracy is 91.00%\n",
      "The precision is 90.20%\n",
      "The recall is 92.00%\n",
      "The F1 score is 91.09%\n",
      "The model got the following rows wrong [14, 31, 36, 54, 83, 92, 94, 98, 105, 108, 109, 120, 153, 159, 161, 168, 181, 185]\n",
      "\n",
      "Cross validation 5\n",
      "The accuracy is 85.00%\n",
      "The precision is 88.04%\n",
      "The recall is 81.00%\n",
      "The F1 score is 84.38%\n",
      "The model got the following rows wrong [0, 5, 18, 19, 20, 26, 30, 32, 35, 36, 51, 55, 60, 64, 67, 91, 93, 95, 98, 109, 144, 155, 160, 167, 172, 186, 189, 191, 192, 199]\n",
      "\n",
      "Cross validation 6\n",
      "The accuracy is 89.00%\n",
      "The precision is 93.33%\n",
      "The recall is 84.00%\n",
      "The F1 score is 88.42%\n",
      "The model got the following rows wrong [1, 2, 7, 19, 32, 34, 39, 40, 41, 45, 63, 79, 80, 85, 90, 99, 102, 119, 147, 151, 158, 171]\n",
      "\n",
      "Cross validation 7\n",
      "The accuracy is 85.50%\n",
      "The precision is 83.81%\n",
      "The recall is 88.00%\n",
      "The F1 score is 85.85%\n",
      "The model got the following rows wrong [3, 6, 27, 32, 34, 43, 44, 55, 60, 65, 93, 99, 100, 104, 109, 117, 120, 122, 126, 135, 137, 145, 161, 166, 171, 182, 185, 187, 197]\n",
      "\n",
      "Cross validation 8\n",
      "The accuracy is 89.00%\n",
      "The precision is 90.62%\n",
      "The recall is 87.00%\n",
      "The F1 score is 88.78%\n",
      "The model got the following rows wrong [12, 17, 19, 21, 35, 40, 58, 61, 64, 81, 89, 90, 97, 109, 112, 117, 135, 142, 166, 172, 187, 191]\n",
      "\n",
      "Cross validation 9\n",
      "The accuracy is 88.50%\n",
      "The precision is 88.89%\n",
      "The recall is 88.00%\n",
      "The F1 score is 88.44%\n",
      "The model got the following rows wrong [16, 25, 42, 50, 52, 55, 56, 70, 74, 76, 82, 84, 101, 103, 126, 132, 144, 145, 151, 155, 176, 178, 190]\n",
      "\n",
      "Cross validation 10\n",
      "The accuracy is 92.50%\n",
      "The precision is 88.99%\n",
      "The recall is 97.00%\n",
      "The F1 score is 92.82%\n",
      "The model got the following rows wrong [47, 50, 63, 112, 117, 124, 128, 133, 167, 171, 186, 188, 190, 192, 195]\n",
      "\n",
      "The average accuracy is 89.30%\n",
      "The average precision is 88.99%\n",
      "The average recall is 89.80%\n",
      "The average F1 score is 89.31%\n"
     ]
    }
   ],
   "source": [
    "print_averages(dataframes_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation 1\n",
      "The accuracy is 93.50%\n",
      "The precision is 95.79%\n",
      "The recall is 91.00%\n",
      "The F1 score is 93.33%\n",
      "The model got the following rows wrong [1, 4, 10, 24, 25, 44, 50, 82, 91, 118, 135, 157, 171]\n",
      "\n",
      "Cross validation 2\n",
      "The accuracy is 92.50%\n",
      "The precision is 92.08%\n",
      "The recall is 93.00%\n",
      "The F1 score is 92.54%\n",
      "The model got the following rows wrong [9, 18, 59, 62, 88, 93, 94, 104, 115, 125, 137, 142, 167, 177, 189]\n",
      "\n",
      "Cross validation 3\n",
      "The accuracy is 93.00%\n",
      "The precision is 90.57%\n",
      "The recall is 96.00%\n",
      "The F1 score is 93.20%\n",
      "The model got the following rows wrong [8, 30, 50, 99, 100, 107, 111, 121, 133, 137, 142, 156, 162, 178]\n",
      "\n",
      "Cross validation 4\n",
      "The accuracy is 92.50%\n",
      "The precision is 92.93%\n",
      "The recall is 92.00%\n",
      "The F1 score is 92.46%\n",
      "The model got the following rows wrong [7, 14, 21, 34, 70, 83, 94, 98, 105, 109, 120, 128, 131, 159, 181]\n",
      "\n",
      "Cross validation 5\n",
      "The accuracy is 88.50%\n",
      "The precision is 89.69%\n",
      "The recall is 87.00%\n",
      "The F1 score is 88.32%\n",
      "The model got the following rows wrong [0, 19, 20, 26, 30, 35, 36, 37, 51, 55, 67, 77, 98, 100, 109, 130, 144, 155, 162, 172, 189, 192, 199]\n",
      "\n",
      "Cross validation 6\n",
      "The accuracy is 93.50%\n",
      "The precision is 97.80%\n",
      "The recall is 89.00%\n",
      "The F1 score is 93.19%\n",
      "The model got the following rows wrong [2, 7, 34, 39, 41, 45, 63, 80, 85, 90, 99, 133, 171]\n",
      "\n",
      "Cross validation 7\n",
      "The accuracy is 90.50%\n",
      "The precision is 89.32%\n",
      "The recall is 92.00%\n",
      "The F1 score is 90.64%\n",
      "The model got the following rows wrong [6, 27, 32, 42, 43, 44, 49, 93, 100, 102, 109, 117, 118, 126, 145, 171, 177, 185, 197]\n",
      "\n",
      "Cross validation 8\n",
      "The accuracy is 90.00%\n",
      "The precision is 87.74%\n",
      "The recall is 93.00%\n",
      "The F1 score is 90.29%\n",
      "The model got the following rows wrong [35, 58, 61, 74, 89, 90, 92, 104, 109, 119, 129, 131, 132, 134, 135, 142, 169, 185, 196, 197]\n",
      "\n",
      "Cross validation 9\n",
      "The accuracy is 91.50%\n",
      "The precision is 96.63%\n",
      "The recall is 86.00%\n",
      "The F1 score is 91.01%\n",
      "The model got the following rows wrong [16, 19, 25, 40, 41, 50, 55, 56, 59, 76, 81, 82, 84, 93, 101, 103, 145]\n",
      "\n",
      "Cross validation 10\n",
      "The accuracy is 95.00%\n",
      "The precision is 95.92%\n",
      "The recall is 94.00%\n",
      "The F1 score is 94.95%\n",
      "The model got the following rows wrong [7, 29, 32, 40, 47, 63, 112, 121, 127, 141]\n",
      "\n",
      "The average accuracy is 92.05%\n",
      "The average precision is 92.85%\n",
      "The average recall is 91.30%\n",
      "The average F1 score is 91.99%\n"
     ]
    }
   ],
   "source": [
    "print_averages(dataframes_512_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation 1\n",
      "The accuracy is 90.00%\n",
      "The precision is 90.82%\n",
      "The recall is 89.00%\n",
      "The F1 score is 89.90%\n",
      "The model got the following rows wrong [1, 10, 24, 25, 40, 44, 50, 56, 82, 83, 91, 106, 118, 134, 135, 136, 157, 159, 171, 173]\n",
      "\n",
      "Cross validation 2\n",
      "The accuracy is 93.50%\n",
      "The precision is 91.43%\n",
      "The recall is 96.00%\n",
      "The F1 score is 93.66%\n",
      "The model got the following rows wrong [9, 59, 88, 94, 104, 115, 125, 137, 142, 146, 167, 177, 189]\n",
      "\n",
      "Cross validation 3\n",
      "The accuracy is 92.00%\n",
      "The precision is 89.62%\n",
      "The recall is 95.00%\n",
      "The F1 score is 92.23%\n",
      "The model got the following rows wrong [8, 30, 50, 62, 99, 100, 107, 121, 128, 133, 142, 147, 156, 162, 173, 178]\n",
      "\n",
      "Cross validation 4\n",
      "The accuracy is 87.50%\n",
      "The precision is 87.88%\n",
      "The recall is 87.00%\n",
      "The F1 score is 87.44%\n",
      "The model got the following rows wrong [7, 14, 21, 27, 28, 30, 34, 39, 70, 83, 85, 94, 98, 108, 109, 120, 121, 128, 131, 133, 159, 163, 179, 181, 191]\n",
      "\n",
      "Cross validation 5\n",
      "The accuracy is 87.50%\n",
      "The precision is 88.66%\n",
      "The recall is 86.00%\n",
      "The F1 score is 87.31%\n",
      "The model got the following rows wrong [0, 18, 19, 20, 26, 30, 35, 36, 37, 51, 55, 67, 77, 98, 100, 109, 130, 131, 144, 155, 162, 172, 189, 192, 199]\n",
      "\n",
      "Cross validation 6\n",
      "The accuracy is 93.50%\n",
      "The precision is 93.94%\n",
      "The recall is 93.00%\n",
      "The F1 score is 93.47%\n",
      "The model got the following rows wrong [2, 4, 7, 34, 79, 85, 99, 119, 124, 133, 143, 154, 171]\n",
      "\n",
      "Cross validation 7\n",
      "The accuracy is 90.50%\n",
      "The precision is 87.16%\n",
      "The recall is 95.00%\n",
      "The F1 score is 90.91%\n",
      "The model got the following rows wrong [6, 32, 43, 44, 93, 100, 102, 109, 117, 118, 122, 126, 145, 147, 150, 155, 171, 185, 197]\n",
      "\n",
      "Cross validation 8\n",
      "The accuracy is 89.00%\n",
      "The precision is 86.11%\n",
      "The recall is 93.00%\n",
      "The F1 score is 89.42%\n",
      "The model got the following rows wrong [21, 35, 58, 74, 89, 90, 92, 104, 108, 109, 119, 122, 129, 131, 132, 134, 135, 142, 169, 185, 196, 197]\n",
      "\n",
      "Cross validation 9\n",
      "The accuracy is 92.00%\n",
      "The precision is 94.68%\n",
      "The recall is 89.00%\n",
      "The F1 score is 91.75%\n",
      "The model got the following rows wrong [10, 16, 25, 41, 55, 56, 59, 76, 81, 82, 93, 101, 103, 105, 145, 186]\n",
      "\n",
      "Cross validation 10\n",
      "The accuracy is 96.00%\n",
      "The precision is 98.94%\n",
      "The recall is 93.00%\n",
      "The F1 score is 95.88%\n",
      "The model got the following rows wrong [7, 11, 29, 32, 36, 47, 63, 112]\n",
      "\n",
      "The average accuracy is 91.15%\n",
      "The average precision is 90.92%\n",
      "The average recall is 91.60%\n",
      "The average F1 score is 91.20%\n"
     ]
    }
   ],
   "source": [
    "print_averages(dataframes_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrects_bert = scores[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 41)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrects_bert), len(incorrects_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "50\n",
      "82\n",
      "108\n",
      "124\n",
      "134\n",
      "135\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(incorrects_nb)):\n",
    "    if incorrects_nb[i] in incorrects_bert:\n",
    "        print(incorrects_nb[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. jock\\'s airplane at the beginning of the film has the registration number \" ob-cpo \" . this is a reference to obi-wan and c-3po from george lucas\\' star wars ( 9 . 5/10 ) . also , the hieroglyphics in the well of souls include engravings of r2-d2 and c-3po . they can be seen on a post to the right of indy and sallah as they remove the ark . the script originally included a long fight between a swordsman and indiana with his whip . as legend has it , actor harrison ford was suffering diarrhea at the time , and asked if the scene could be shortened . spielberg said the only way he could shorten it was if indy pulled out his gun and just shot the guy . the entire crew laughed and that\\'s how it was filmed . when indy first falls in the well of souls and is face to face with the cobra , you can see the snake\\'s reflection on the glass dividing it and harrison ford , also some fingerprints and stuff like that . when indy is dragging along the ground , hanging onto the nazi soldier\\'s truck with the ark inside , you can see the pad that he\\'s being dragged on . '"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[44]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['what',\n",
       "   'do',\n",
       "   'you',\n",
       "   'get',\n",
       "   'when',\n",
       "   'you',\n",
       "   'slap',\n",
       "   'together',\n",
       "   'a',\n",
       "   'movie',\n",
       "   'based',\n",
       "   'on',\n",
       "   'a',\n",
       "   'story',\n",
       "   'by',\n",
       "   'the',\n",
       "   'legendary',\n",
       "   'george',\n",
       "   'lucas',\n",
       "   ',',\n",
       "   'directed',\n",
       "   'by',\n",
       "   'virtuoso',\n",
       "   'director',\n",
       "   'steven',\n",
       "   'spielberg',\n",
       "   ',',\n",
       "   'and',\n",
       "   'starring',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   'biggest',\n",
       "   'box-office',\n",
       "   'stars',\n",
       "   'in',\n",
       "   'the',\n",
       "   'world',\n",
       "   ',',\n",
       "   'harrison',\n",
       "   'ford',\n",
       "   '?'],\n",
       "  ['you',\n",
       "   'get',\n",
       "   'one',\n",
       "   \"hot-fudge-rockin'\",\n",
       "   'good',\n",
       "   'time',\n",
       "   ',',\n",
       "   \"that's\",\n",
       "   'what',\n",
       "   'you',\n",
       "   'get',\n",
       "   '!',\n",
       "   '!',\n",
       "   '!'],\n",
       "  ['plot',\n",
       "   ':',\n",
       "   'professor/archeologist',\n",
       "   'indiana',\n",
       "   'jones',\n",
       "   'sets',\n",
       "   'out',\n",
       "   'to',\n",
       "   'find',\n",
       "   'the',\n",
       "   'long-lost',\n",
       "   'mystical',\n",
       "   'ark',\n",
       "   'of',\n",
       "   'the',\n",
       "   'covenant',\n",
       "   'before',\n",
       "   'the',\n",
       "   'nazis',\n",
       "   'get',\n",
       "   'their',\n",
       "   'grubby',\n",
       "   'fingers',\n",
       "   'hands',\n",
       "   'on',\n",
       "   'it',\n",
       "   '.'],\n",
       "  ['adventures',\n",
       "   ',',\n",
       "   'snakes',\n",
       "   ',',\n",
       "   'romance',\n",
       "   'and',\n",
       "   'mucho',\n",
       "   'action',\n",
       "   'ensues',\n",
       "   '.'],\n",
       "  ['critique',\n",
       "   ':',\n",
       "   'astounding',\n",
       "   'movie',\n",
       "   'packed',\n",
       "   'with',\n",
       "   'non-stop',\n",
       "   'action',\n",
       "   ',',\n",
       "   'stunts',\n",
       "   'galore',\n",
       "   ',',\n",
       "   'an',\n",
       "   'interesting',\n",
       "   'story',\n",
       "   'line',\n",
       "   ',',\n",
       "   'great',\n",
       "   'one-liners',\n",
       "   ',',\n",
       "   'a',\n",
       "   'solid',\n",
       "   'cast',\n",
       "   ',',\n",
       "   'a',\n",
       "   'catchy',\n",
       "   'musical',\n",
       "   'score',\n",
       "   ',',\n",
       "   'and',\n",
       "   'all',\n",
       "   'the',\n",
       "   'fun',\n",
       "   'and',\n",
       "   'adventure',\n",
       "   'that',\n",
       "   'you',\n",
       "   'could',\n",
       "   'squeeze',\n",
       "   'into',\n",
       "   'a',\n",
       "   'two-hour',\n",
       "   'thrill',\n",
       "   'ride',\n",
       "   '.'],\n",
       "  ['if',\n",
       "   'you',\n",
       "   \"don't\",\n",
       "   'enjoy',\n",
       "   'this',\n",
       "   'film',\n",
       "   ',',\n",
       "   'then',\n",
       "   'you',\n",
       "   'just',\n",
       "   \"don't\",\n",
       "   'like',\n",
       "   'action',\n",
       "   'movies',\n",
       "   ',',\n",
       "   'period',\n",
       "   '!'],\n",
       "  ['if',\n",
       "   \"you're\",\n",
       "   'young',\n",
       "   ',',\n",
       "   \"you'll\",\n",
       "   'enjoy',\n",
       "   'its',\n",
       "   'humor',\n",
       "   ',',\n",
       "   'its',\n",
       "   'cool',\n",
       "   'action',\n",
       "   'sequences',\n",
       "   'and',\n",
       "   'its',\n",
       "   'gross-out',\n",
       "   'factor',\n",
       "   'at',\n",
       "   'times',\n",
       "   '.'],\n",
       "  ['if',\n",
       "   \"you're\",\n",
       "   'a',\n",
       "   'little',\n",
       "   'older',\n",
       "   ',',\n",
       "   \"you'll\",\n",
       "   'appreciate',\n",
       "   'the',\n",
       "   'interesting',\n",
       "   'plot',\n",
       "   'line',\n",
       "   ',',\n",
       "   'the',\n",
       "   'romance',\n",
       "   ',',\n",
       "   'and',\n",
       "   'yes',\n",
       "   ',',\n",
       "   'the',\n",
       "   'mountains',\n",
       "   'of',\n",
       "   'adventure',\n",
       "   '.'],\n",
       "  ['watching',\n",
       "   'this',\n",
       "   'movie',\n",
       "   'made',\n",
       "   'me',\n",
       "   'feel',\n",
       "   'like',\n",
       "   'a',\n",
       "   'kid',\n",
       "   'again',\n",
       "   ',',\n",
       "   'dreaming',\n",
       "   'and',\n",
       "   'fantasizing',\n",
       "   'about',\n",
       "   'fighting',\n",
       "   'the',\n",
       "   'bad',\n",
       "   'guys',\n",
       "   ',',\n",
       "   'travelling',\n",
       "   'to',\n",
       "   'different',\n",
       "   'countries',\n",
       "   ',',\n",
       "   'making',\n",
       "   'the',\n",
       "   'impossible',\n",
       "   ',',\n",
       "   'possible',\n",
       "   '!'],\n",
       "  ['harrison',\n",
       "   'ford',\n",
       "   'is',\n",
       "   'perfect',\n",
       "   'as',\n",
       "   'the',\n",
       "   'every-man',\n",
       "   'with',\n",
       "   'the',\n",
       "   'brains',\n",
       "   'of',\n",
       "   'a',\n",
       "   'scientist',\n",
       "   'and',\n",
       "   'the',\n",
       "   'brawn',\n",
       "   'of',\n",
       "   'an',\n",
       "   'outdoors',\n",
       "   'adventurer',\n",
       "   ',',\n",
       "   'and',\n",
       "   'spielberg',\n",
       "   'manages',\n",
       "   'to',\n",
       "   'achieve',\n",
       "   'the',\n",
       "   'ideal',\n",
       "   'balance',\n",
       "   'of',\n",
       "   'action',\n",
       "   ',',\n",
       "   'fun',\n",
       "   ',',\n",
       "   'adventure',\n",
       "   'and',\n",
       "   'humor',\n",
       "   '.'],\n",
       "  ['now',\n",
       "   'if',\n",
       "   'you',\n",
       "   'really',\n",
       "   'want',\n",
       "   'to',\n",
       "   'have',\n",
       "   'a',\n",
       "   'good',\n",
       "   'time',\n",
       "   ',',\n",
       "   'check',\n",
       "   'into',\n",
       "   'this',\n",
       "   'movie',\n",
       "   'on',\n",
       "   'the',\n",
       "   'same',\n",
       "   'night',\n",
       "   'as',\n",
       "   'its',\n",
       "   'two',\n",
       "   'sequels',\n",
       "   ',',\n",
       "   'rent',\n",
       "   'a',\n",
       "   'jug',\n",
       "   'of',\n",
       "   'iced',\n",
       "   'coke',\n",
       "   ',',\n",
       "   'truckloads',\n",
       "   'of',\n",
       "   'nachos',\n",
       "   'and',\n",
       "   'salsa',\n",
       "   ',',\n",
       "   'an',\n",
       "   'adventure',\n",
       "   'hat',\n",
       "   'and',\n",
       "   'whip',\n",
       "   ',',\n",
       "   'and',\n",
       "   'prepare',\n",
       "   'to',\n",
       "   'gag',\n",
       "   'yourself',\n",
       "   'into',\n",
       "   'a',\n",
       "   'world',\n",
       "   'of',\n",
       "   'action-movie',\n",
       "   'heaven',\n",
       "   '!'],\n",
       "  ['little',\n",
       "   'known',\n",
       "   'facts',\n",
       "   'about',\n",
       "   'this',\n",
       "   'film',\n",
       "   'and',\n",
       "   'its',\n",
       "   'stars',\n",
       "   ':',\n",
       "   'this',\n",
       "   'picture',\n",
       "   'was',\n",
       "   'nominated',\n",
       "   'for',\n",
       "   'eight',\n",
       "   '1981',\n",
       "   'oscar',\n",
       "   'nominations',\n",
       "   ',',\n",
       "   'including',\n",
       "   'best',\n",
       "   'picture',\n",
       "   '.'],\n",
       "  ['it',\n",
       "   'lost',\n",
       "   'that',\n",
       "   'award',\n",
       "   'to',\n",
       "   'chariots',\n",
       "   'of',\n",
       "   'fire',\n",
       "   ',',\n",
       "   'but',\n",
       "   'did',\n",
       "   'manage',\n",
       "   'to',\n",
       "   'win',\n",
       "   'for',\n",
       "   'best',\n",
       "   'art',\n",
       "   'direction',\n",
       "   ',',\n",
       "   'best',\n",
       "   'special',\n",
       "   'effects',\n",
       "   ',',\n",
       "   'best',\n",
       "   'film',\n",
       "   'editing',\n",
       "   'and',\n",
       "   'best',\n",
       "   'sound',\n",
       "   '.'],\n",
       "  ['actor',\n",
       "   'tom',\n",
       "   'selleck',\n",
       "   'was',\n",
       "   'originally',\n",
       "   'cast',\n",
       "   'as',\n",
       "   'indiana',\n",
       "   'jones',\n",
       "   ',',\n",
       "   'but',\n",
       "   'was',\n",
       "   'committed',\n",
       "   'to',\n",
       "   'his',\n",
       "   'hit',\n",
       "   'tv',\n",
       "   'show',\n",
       "   ',',\n",
       "   '\"',\n",
       "   'magnum',\n",
       "   'p',\n",
       "   '.',\n",
       "   'i',\n",
       "   '.',\n",
       "   '\"',\n",
       "   '.'],\n",
       "  ['in',\n",
       "   'filming',\n",
       "   'the',\n",
       "   'well',\n",
       "   'of',\n",
       "   'souls',\n",
       "   'sequence',\n",
       "   ',',\n",
       "   'the',\n",
       "   'producers',\n",
       "   'scoured',\n",
       "   'every',\n",
       "   'pet',\n",
       "   'shop',\n",
       "   'in',\n",
       "   'london',\n",
       "   'and',\n",
       "   'the',\n",
       "   'south',\n",
       "   'of',\n",
       "   'england',\n",
       "   'for',\n",
       "   'every',\n",
       "   'snake',\n",
       "   'they',\n",
       "   'could',\n",
       "   'lay',\n",
       "   'their',\n",
       "   'hands',\n",
       "   'on',\n",
       "   '.'],\n",
       "  ['hence',\n",
       "   'there',\n",
       "   'are',\n",
       "   'snakes',\n",
       "   'that',\n",
       "   'are',\n",
       "   'identifiable',\n",
       "   'from',\n",
       "   'many',\n",
       "   'different',\n",
       "   'geographical',\n",
       "   'areas',\n",
       "   '.'],\n",
       "  ['however',\n",
       "   ',',\n",
       "   'once',\n",
       "   'all',\n",
       "   'the',\n",
       "   'snakes',\n",
       "   'were',\n",
       "   'on',\n",
       "   'set',\n",
       "   ',',\n",
       "   'it',\n",
       "   'became',\n",
       "   'clear',\n",
       "   'that',\n",
       "   'there',\n",
       "   'were',\n",
       "   'not',\n",
       "   'nearly',\n",
       "   'enough',\n",
       "   'of',\n",
       "   'them',\n",
       "   ',',\n",
       "   'so',\n",
       "   'spielberg',\n",
       "   'had',\n",
       "   'several',\n",
       "   'hoses',\n",
       "   'cut',\n",
       "   'into',\n",
       "   'lengths',\n",
       "   ',',\n",
       "   'and',\n",
       "   'these',\n",
       "   'were',\n",
       "   'used',\n",
       "   'as',\n",
       "   'well',\n",
       "   '.'],\n",
       "  ['looking',\n",
       "   'closely',\n",
       "   ',',\n",
       "   'you',\n",
       "   'can',\n",
       "   'tell',\n",
       "   'which',\n",
       "   'are',\n",
       "   'the',\n",
       "   'real',\n",
       "   'snakes',\n",
       "   'and',\n",
       "   'which',\n",
       "   'are',\n",
       "   'not',\n",
       "   '.'],\n",
       "  ['an',\n",
       "   'early',\n",
       "   'draft',\n",
       "   'of',\n",
       "   'the',\n",
       "   'script',\n",
       "   'had',\n",
       "   'indy',\n",
       "   'travelling',\n",
       "   'to',\n",
       "   'shanghai',\n",
       "   'to',\n",
       "   'recover',\n",
       "   'a',\n",
       "   'piece',\n",
       "   'of',\n",
       "   'the',\n",
       "   'staff',\n",
       "   'of',\n",
       "   'ra',\n",
       "   '.'],\n",
       "  ['during',\n",
       "   'his',\n",
       "   'escape',\n",
       "   'from',\n",
       "   'the',\n",
       "   'museum',\n",
       "   'where',\n",
       "   'it',\n",
       "   'was',\n",
       "   'housed',\n",
       "   ',',\n",
       "   'he',\n",
       "   'sheltered',\n",
       "   'from',\n",
       "   'machine',\n",
       "   'gun',\n",
       "   'fire',\n",
       "   'behind',\n",
       "   'a',\n",
       "   'giant',\n",
       "   'rolling',\n",
       "   'gong',\n",
       "   '.'],\n",
       "  ['also',\n",
       "   'in',\n",
       "   'the',\n",
       "   'same',\n",
       "   'script',\n",
       "   ',',\n",
       "   'indy',\n",
       "   'and',\n",
       "   'marion',\n",
       "   'flee',\n",
       "   'the',\n",
       "   'chaos',\n",
       "   'caused',\n",
       "   'by',\n",
       "   'the',\n",
       "   'opening',\n",
       "   'of',\n",
       "   'the',\n",
       "   'ark',\n",
       "   'in',\n",
       "   'a',\n",
       "   'wild',\n",
       "   'mine-cart',\n",
       "   'chase',\n",
       "   'sequence',\n",
       "   '.'],\n",
       "  ['both',\n",
       "   'of',\n",
       "   'these',\n",
       "   'scenes',\n",
       "   'were',\n",
       "   'cut',\n",
       "   'from',\n",
       "   'the',\n",
       "   'script',\n",
       "   ',',\n",
       "   'but',\n",
       "   'ended',\n",
       "   'up',\n",
       "   'in',\n",
       "   \"1984's\",\n",
       "   'indiana',\n",
       "   'jones',\n",
       "   'and',\n",
       "   'the',\n",
       "   'temple',\n",
       "   'of',\n",
       "   'doom',\n",
       "   '.'],\n",
       "  ['this',\n",
       "   'film',\n",
       "   'begins',\n",
       "   'with',\n",
       "   'a',\n",
       "   'shot',\n",
       "   'of',\n",
       "   'a',\n",
       "   'peak',\n",
       "   'in',\n",
       "   'the',\n",
       "   'jungle',\n",
       "   'which',\n",
       "   'is',\n",
       "   'reminiscent',\n",
       "   'of',\n",
       "   'the',\n",
       "   'paramount',\n",
       "   'pictures',\n",
       "   'logo',\n",
       "   '.'],\n",
       "  ['the',\n",
       "   'same',\n",
       "   'type',\n",
       "   'of',\n",
       "   'opening',\n",
       "   'is',\n",
       "   'present',\n",
       "   'in',\n",
       "   'its',\n",
       "   'sequels',\n",
       "   '.'],\n",
       "  [\"jock's\",\n",
       "   'airplane',\n",
       "   'at',\n",
       "   'the',\n",
       "   'beginning',\n",
       "   'of',\n",
       "   'the',\n",
       "   'film',\n",
       "   'has',\n",
       "   'the',\n",
       "   'registration',\n",
       "   'number',\n",
       "   '\"',\n",
       "   'ob-cpo',\n",
       "   '\"',\n",
       "   '.'],\n",
       "  ['this',\n",
       "   'is',\n",
       "   'a',\n",
       "   'reference',\n",
       "   'to',\n",
       "   'obi-wan',\n",
       "   'and',\n",
       "   'c-3po',\n",
       "   'from',\n",
       "   'george',\n",
       "   \"lucas'\",\n",
       "   'star',\n",
       "   'wars',\n",
       "   '(',\n",
       "   '9',\n",
       "   '.',\n",
       "   '5/10',\n",
       "   ')',\n",
       "   '.'],\n",
       "  ['also',\n",
       "   ',',\n",
       "   'the',\n",
       "   'hieroglyphics',\n",
       "   'in',\n",
       "   'the',\n",
       "   'well',\n",
       "   'of',\n",
       "   'souls',\n",
       "   'include',\n",
       "   'engravings',\n",
       "   'of',\n",
       "   'r2-d2',\n",
       "   'and',\n",
       "   'c-3po',\n",
       "   '.'],\n",
       "  ['they',\n",
       "   'can',\n",
       "   'be',\n",
       "   'seen',\n",
       "   'on',\n",
       "   'a',\n",
       "   'post',\n",
       "   'to',\n",
       "   'the',\n",
       "   'right',\n",
       "   'of',\n",
       "   'indy',\n",
       "   'and',\n",
       "   'sallah',\n",
       "   'as',\n",
       "   'they',\n",
       "   'remove',\n",
       "   'the',\n",
       "   'ark',\n",
       "   '.'],\n",
       "  ['the',\n",
       "   'script',\n",
       "   'originally',\n",
       "   'included',\n",
       "   'a',\n",
       "   'long',\n",
       "   'fight',\n",
       "   'between',\n",
       "   'a',\n",
       "   'swordsman',\n",
       "   'and',\n",
       "   'indiana',\n",
       "   'with',\n",
       "   'his',\n",
       "   'whip',\n",
       "   '.'],\n",
       "  ['as',\n",
       "   'legend',\n",
       "   'has',\n",
       "   'it',\n",
       "   ',',\n",
       "   'actor',\n",
       "   'harrison',\n",
       "   'ford',\n",
       "   'was',\n",
       "   'suffering',\n",
       "   'diarrhea',\n",
       "   'at',\n",
       "   'the',\n",
       "   'time',\n",
       "   ',',\n",
       "   'and',\n",
       "   'asked',\n",
       "   'if',\n",
       "   'the',\n",
       "   'scene',\n",
       "   'could',\n",
       "   'be',\n",
       "   'shortened',\n",
       "   '.'],\n",
       "  ['spielberg',\n",
       "   'said',\n",
       "   'the',\n",
       "   'only',\n",
       "   'way',\n",
       "   'he',\n",
       "   'could',\n",
       "   'shorten',\n",
       "   'it',\n",
       "   'was',\n",
       "   'if',\n",
       "   'indy',\n",
       "   'pulled',\n",
       "   'out',\n",
       "   'his',\n",
       "   'gun',\n",
       "   'and',\n",
       "   'just',\n",
       "   'shot',\n",
       "   'the',\n",
       "   'guy',\n",
       "   '.'],\n",
       "  ['the',\n",
       "   'entire',\n",
       "   'crew',\n",
       "   'laughed',\n",
       "   'and',\n",
       "   \"that's\",\n",
       "   'how',\n",
       "   'it',\n",
       "   'was',\n",
       "   'filmed',\n",
       "   '.'],\n",
       "  ['when',\n",
       "   'indy',\n",
       "   'first',\n",
       "   'falls',\n",
       "   'in',\n",
       "   'the',\n",
       "   'well',\n",
       "   'of',\n",
       "   'souls',\n",
       "   'and',\n",
       "   'is',\n",
       "   'face',\n",
       "   'to',\n",
       "   'face',\n",
       "   'with',\n",
       "   'the',\n",
       "   'cobra',\n",
       "   ',',\n",
       "   'you',\n",
       "   'can',\n",
       "   'see',\n",
       "   'the',\n",
       "   \"snake's\",\n",
       "   'reflection',\n",
       "   'on',\n",
       "   'the',\n",
       "   'glass',\n",
       "   'dividing',\n",
       "   'it',\n",
       "   'and',\n",
       "   'harrison',\n",
       "   'ford',\n",
       "   ',',\n",
       "   'also',\n",
       "   'some',\n",
       "   'fingerprints',\n",
       "   'and',\n",
       "   'stuff',\n",
       "   'like',\n",
       "   'that',\n",
       "   '.'],\n",
       "  ['when',\n",
       "   'indy',\n",
       "   'is',\n",
       "   'dragging',\n",
       "   'along',\n",
       "   'the',\n",
       "   'ground',\n",
       "   ',',\n",
       "   'hanging',\n",
       "   'onto',\n",
       "   'the',\n",
       "   'nazi',\n",
       "   \"soldier's\",\n",
       "   'truck',\n",
       "   'with',\n",
       "   'the',\n",
       "   'ark',\n",
       "   'inside',\n",
       "   ',',\n",
       "   'you',\n",
       "   'can',\n",
       "   'see',\n",
       "   'the',\n",
       "   'pad',\n",
       "   'that',\n",
       "   \"he's\",\n",
       "   'being',\n",
       "   'dragged',\n",
       "   'on',\n",
       "   '.']],\n",
       " 'pos')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0][1][44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold                                                     pos\n",
       "pred                                                     neg\n",
       "correct                                                   no\n",
       "text       , and boon is the comedian . he's got a steady...\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', and boon is the comedian . he\\'s got a steady-date , katy ( karen allen ) , but she\\'s sick of playing second-fiddle to a bottle of j . d . then there are the others : pinto , a wimp ; flounder , a blimp ; d . day , a biker ; stork , who may or may not have brain-damage ; and last but not least . . . bluto ! bluto , played by the late , great john belushi , is the man . he\\'s the kind of guy who slugs back entire fifths of whiskey then proclaim , \" i needed that . \" the kind of guy who puts a cream-filled snowball into his mouth , puffs up his cheeks and spits it out , and then says \" i\\'m a zit -- get it ? \" the story is as follows : the omegas are getting the deltas kicked off campus . the deltas , knowing that fighting the omegas is stupid , decide to go out with style , throwing a wild toga party and ruining the homecoming parade . this is the fucnniest movie int he history of the world . do yourself a favor and go see it . '"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[50]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['national',\n",
       "   \"lampoon's\",\n",
       "   'animal',\n",
       "   'house',\n",
       "   ',',\n",
       "   'made',\n",
       "   'in',\n",
       "   '1978',\n",
       "   'and',\n",
       "   'set',\n",
       "   'in',\n",
       "   '1962',\n",
       "   ',',\n",
       "   'remains',\n",
       "   'one',\n",
       "   'of',\n",
       "   'the',\n",
       "   '--',\n",
       "   'no',\n",
       "   ',',\n",
       "   'fuck',\n",
       "   'that',\n",
       "   'noise',\n",
       "   '--',\n",
       "   '*',\n",
       "   'the',\n",
       "   '*',\n",
       "   'funniest',\n",
       "   'movie',\n",
       "   'ever',\n",
       "   'made',\n",
       "   '.'],\n",
       "  ['and',\n",
       "   'this',\n",
       "   \"isn't\",\n",
       "   'just',\n",
       "   'my',\n",
       "   'opinion',\n",
       "   ',',\n",
       "   'either',\n",
       "   ';',\n",
       "   'everybody',\n",
       "   'knows',\n",
       "   'this',\n",
       "   ',',\n",
       "   'and',\n",
       "   \"that's\",\n",
       "   'why',\n",
       "   'about',\n",
       "   'a',\n",
       "   'gazillion',\n",
       "   'inferior',\n",
       "   'rip-offs',\n",
       "   'have',\n",
       "   'been',\n",
       "   'made',\n",
       "   ',',\n",
       "   'trying',\n",
       "   'to',\n",
       "   'duplicate',\n",
       "   'its',\n",
       "   'success',\n",
       "   '.'],\n",
       "  ['(', 'pcu', 'anyone', '?'],\n",
       "  ['and',\n",
       "   'the',\n",
       "   'first',\n",
       "   'person',\n",
       "   'to',\n",
       "   'bring',\n",
       "   'up',\n",
       "   'glory',\n",
       "   'daze',\n",
       "   'gets',\n",
       "   'decked',\n",
       "   '.',\n",
       "   ')'],\n",
       "  ['animal',\n",
       "   'house',\n",
       "   'takes',\n",
       "   'place',\n",
       "   'at',\n",
       "   'the',\n",
       "   'fictional',\n",
       "   'faber',\n",
       "   'college',\n",
       "   ',',\n",
       "   'circa',\n",
       "   '1962',\n",
       "   ',',\n",
       "   'where',\n",
       "   'the',\n",
       "   'omega',\n",
       "   'frat',\n",
       "   'calls',\n",
       "   'the',\n",
       "   'shots',\n",
       "   '.'],\n",
       "  ['these',\n",
       "   'guys',\n",
       "   'are',\n",
       "   'wholesome',\n",
       "   ',',\n",
       "   'clean-cut',\n",
       "   ',',\n",
       "   'model-citizens',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.'],\n",
       "  ['i', '.', 'e', '.'],\n",
       "  ['a', 'bunch', 'of', 'assholes', '.'],\n",
       "  ['greg',\n",
       "   ',',\n",
       "   'their',\n",
       "   'leader',\n",
       "   ',',\n",
       "   'is',\n",
       "   'going',\n",
       "   'out',\n",
       "   'with',\n",
       "   'mandy',\n",
       "   'pepperidge',\n",
       "   ',',\n",
       "   'but',\n",
       "   'since',\n",
       "   'the',\n",
       "   'silly',\n",
       "   'bastard',\n",
       "   \"doesn't\",\n",
       "   'believe',\n",
       "   'in',\n",
       "   'pre-marital',\n",
       "   'sex',\n",
       "   ',',\n",
       "   'their',\n",
       "   'relationship',\n",
       "   'never',\n",
       "   'goes',\n",
       "   'further',\n",
       "   'than',\n",
       "   'a',\n",
       "   'quick',\n",
       "   'jack-off',\n",
       "   'under',\n",
       "   'the',\n",
       "   'stars',\n",
       "   '.'],\n",
       "  ['neidermeyer',\n",
       "   'is',\n",
       "   'the',\n",
       "   'supreme-bozo',\n",
       "   'of',\n",
       "   'the',\n",
       "   'bunch',\n",
       "   ',',\n",
       "   'walking',\n",
       "   'around',\n",
       "   'with',\n",
       "   'his',\n",
       "   'dick',\n",
       "   'out',\n",
       "   'kicking',\n",
       "   'freshman',\n",
       "   'ass',\n",
       "   'and',\n",
       "   'trying',\n",
       "   'to',\n",
       "   'impress',\n",
       "   'the',\n",
       "   'muff',\n",
       "   '.'],\n",
       "  ['also',\n",
       "   'hanging',\n",
       "   'around',\n",
       "   'these',\n",
       "   'losers',\n",
       "   'is',\n",
       "   'babs',\n",
       "   ',',\n",
       "   'future',\n",
       "   'universal',\n",
       "   'studios',\n",
       "   'employee',\n",
       "   'and',\n",
       "   'serious',\n",
       "   'bitch',\n",
       "   '.'],\n",
       "  ['now',\n",
       "   \"let's\",\n",
       "   'just',\n",
       "   'take',\n",
       "   'a',\n",
       "   'peak',\n",
       "   'next',\n",
       "   'door',\n",
       "   ',',\n",
       "   'at',\n",
       "   'the',\n",
       "   'delta',\n",
       "   'house',\n",
       "   '.'],\n",
       "  ['over',\n",
       "   'here',\n",
       "   ',',\n",
       "   'anything',\n",
       "   'goes',\n",
       "   ':',\n",
       "   'you',\n",
       "   'wanna',\n",
       "   'throw',\n",
       "   'shit',\n",
       "   'out',\n",
       "   'the',\n",
       "   'window',\n",
       "   '?'],\n",
       "  ['okay', '.'],\n",
       "  ['you',\n",
       "   'wanna',\n",
       "   'crush',\n",
       "   'a',\n",
       "   'bunch',\n",
       "   'of',\n",
       "   'beer',\n",
       "   'cans',\n",
       "   'on',\n",
       "   'your',\n",
       "   'forehead',\n",
       "   'and',\n",
       "   'pour',\n",
       "   'honey-mustard',\n",
       "   'all',\n",
       "   'over',\n",
       "   'your',\n",
       "   'chest',\n",
       "   '?'],\n",
       "  ['go', 'right', 'ahead', '.'],\n",
       "  ['the',\n",
       "   \"frat's\",\n",
       "   'leaders',\n",
       "   'are',\n",
       "   'otter',\n",
       "   'and',\n",
       "   'boon',\n",
       "   '(',\n",
       "   'tim',\n",
       "   'matheson',\n",
       "   'and',\n",
       "   'peter',\n",
       "   'riegert',\n",
       "   ')',\n",
       "   '.'],\n",
       "  ['otter',\n",
       "   'is',\n",
       "   'the',\n",
       "   \"ladies'\",\n",
       "   'man',\n",
       "   ',',\n",
       "   'going',\n",
       "   'out',\n",
       "   'with',\n",
       "   'another',\n",
       "   'girl',\n",
       "   'every',\n",
       "   'night',\n",
       "   ',',\n",
       "   'and',\n",
       "   'boon',\n",
       "   'is',\n",
       "   'the',\n",
       "   'comedian',\n",
       "   '.'],\n",
       "  [\"he's\",\n",
       "   'got',\n",
       "   'a',\n",
       "   'steady-date',\n",
       "   ',',\n",
       "   'katy',\n",
       "   '(',\n",
       "   'karen',\n",
       "   'allen',\n",
       "   ')',\n",
       "   ',',\n",
       "   'but',\n",
       "   \"she's\",\n",
       "   'sick',\n",
       "   'of',\n",
       "   'playing',\n",
       "   'second-fiddle',\n",
       "   'to',\n",
       "   'a',\n",
       "   'bottle',\n",
       "   'of',\n",
       "   'j',\n",
       "   '.',\n",
       "   'd',\n",
       "   '.'],\n",
       "  ['then',\n",
       "   'there',\n",
       "   'are',\n",
       "   'the',\n",
       "   'others',\n",
       "   ':',\n",
       "   'pinto',\n",
       "   ',',\n",
       "   'a',\n",
       "   'wimp',\n",
       "   ';',\n",
       "   'flounder',\n",
       "   ',',\n",
       "   'a',\n",
       "   'blimp',\n",
       "   ';',\n",
       "   'd',\n",
       "   '.',\n",
       "   'day',\n",
       "   ',',\n",
       "   'a',\n",
       "   'biker',\n",
       "   ';',\n",
       "   'stork',\n",
       "   ',',\n",
       "   'who',\n",
       "   'may',\n",
       "   'or',\n",
       "   'may',\n",
       "   'not',\n",
       "   'have',\n",
       "   'brain-damage',\n",
       "   ';',\n",
       "   'and',\n",
       "   'last',\n",
       "   'but',\n",
       "   'not',\n",
       "   'least',\n",
       "   '.',\n",
       "   '.',\n",
       "   '.'],\n",
       "  ['bluto', '!'],\n",
       "  ['bluto',\n",
       "   ',',\n",
       "   'played',\n",
       "   'by',\n",
       "   'the',\n",
       "   'late',\n",
       "   ',',\n",
       "   'great',\n",
       "   'john',\n",
       "   'belushi',\n",
       "   ',',\n",
       "   'is',\n",
       "   'the',\n",
       "   'man',\n",
       "   '.'],\n",
       "  [\"he's\",\n",
       "   'the',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'guy',\n",
       "   'who',\n",
       "   'slugs',\n",
       "   'back',\n",
       "   'entire',\n",
       "   'fifths',\n",
       "   'of',\n",
       "   'whiskey',\n",
       "   'then',\n",
       "   'proclaim',\n",
       "   ',',\n",
       "   '\"',\n",
       "   'i',\n",
       "   'needed',\n",
       "   'that',\n",
       "   '.',\n",
       "   '\"'],\n",
       "  ['the',\n",
       "   'kind',\n",
       "   'of',\n",
       "   'guy',\n",
       "   'who',\n",
       "   'puts',\n",
       "   'a',\n",
       "   'cream-filled',\n",
       "   'snowball',\n",
       "   'into',\n",
       "   'his',\n",
       "   'mouth',\n",
       "   ',',\n",
       "   'puffs',\n",
       "   'up',\n",
       "   'his',\n",
       "   'cheeks',\n",
       "   'and',\n",
       "   'spits',\n",
       "   'it',\n",
       "   'out',\n",
       "   ',',\n",
       "   'and',\n",
       "   'then',\n",
       "   'says',\n",
       "   '\"',\n",
       "   \"i'm\",\n",
       "   'a',\n",
       "   'zit',\n",
       "   '--',\n",
       "   'get',\n",
       "   'it',\n",
       "   '?',\n",
       "   '\"'],\n",
       "  ['the',\n",
       "   'story',\n",
       "   'is',\n",
       "   'as',\n",
       "   'follows',\n",
       "   ':',\n",
       "   'the',\n",
       "   'omegas',\n",
       "   'are',\n",
       "   'getting',\n",
       "   'the',\n",
       "   'deltas',\n",
       "   'kicked',\n",
       "   'off',\n",
       "   'campus',\n",
       "   '.'],\n",
       "  ['the',\n",
       "   'deltas',\n",
       "   ',',\n",
       "   'knowing',\n",
       "   'that',\n",
       "   'fighting',\n",
       "   'the',\n",
       "   'omegas',\n",
       "   'is',\n",
       "   'stupid',\n",
       "   ',',\n",
       "   'decide',\n",
       "   'to',\n",
       "   'go',\n",
       "   'out',\n",
       "   'with',\n",
       "   'style',\n",
       "   ',',\n",
       "   'throwing',\n",
       "   'a',\n",
       "   'wild',\n",
       "   'toga',\n",
       "   'party',\n",
       "   'and',\n",
       "   'ruining',\n",
       "   'the',\n",
       "   'homecoming',\n",
       "   'parade',\n",
       "   '.'],\n",
       "  ['this',\n",
       "   'is',\n",
       "   'the',\n",
       "   'fucnniest',\n",
       "   'movie',\n",
       "   'int',\n",
       "   'he',\n",
       "   'history',\n",
       "   'of',\n",
       "   'the',\n",
       "   'world',\n",
       "   '.'],\n",
       "  ['do', 'yourself', 'a', 'favor', 'and', 'go', 'see', 'it', '.']],\n",
       " 'pos')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0][1][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold                                                     pos\n",
       "pred                                                     neg\n",
       "correct                                                   no\n",
       "text       less music , and john landis seems to have los...\n",
       "Name: 82, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'less music , and john landis seems to have lost interest in the whole thing . there\\'s a few early crashes , and then one huge pile-up , but after that it all stops . it\\'s just the music . one of my problems with the first is that cab calloway\\'s song is so good the actually blues brothers look dull after him , but there\\'s no problems with this . the music is all as good as ever , tons of great musicians showing up -- with the exception of johnny lang , who can\\'t sing , all the musicians do a great job . the only real problems i had was the special effects . these were superfluous and a waste of money . since the film isn\\'t doing very well , they could mean we have no possibility of another sequel , which i want to see . the bluegrass version of riders in the sky is even better than rawhide . -- http : //www . geocities . com/hollywood/academy/8034/ remove no spam to reply . \" drive carefully but recklessly \" , mama , child\\'s toy \" the only excercise i take is walking behind the coffins of friends who took exercise . \" peter o\\'toole '"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[82]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
