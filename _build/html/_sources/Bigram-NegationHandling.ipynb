{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams with Negation Handling\n",
    "\n",
    "The idea of this section was to use the same setups for the bigram section, but use the dataset created for the negation handling section. \n",
    "\n",
    "The beginning essentially does the set up for this, creating and loading this negation handled dataset and building the model creation structure for bigrams instead of unigrams.\n",
    "\n",
    "With this in mind, it's once again best to skip down to the \"Naive Bayes\" subheading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "pos_path = \"./data/txt_sentoken/pos/\"\n",
    "pos_path_out = \"./data/txt_sentoken_negation/pos_negation/\"\n",
    "neg_path = \"./data/txt_sentoken/neg/\"\n",
    "neg_path_out = \"./data/txt_sentoken_negation/neg_negation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_negation(in_path, out_path):\n",
    "    file_list = os.listdir(in_path)\n",
    "    for file in file_list:\n",
    "        new_file = file + \"_new.txt\"\n",
    "        new_file_sentences = []\n",
    "        with open(in_path + file, 'r') as f, open(out_path + new_file, 'w+') as f_out:\n",
    "            for line in f.readlines():\n",
    "                new_line = ''\n",
    "                tokens = line.split()\n",
    "                i = 0\n",
    "                while i < len(tokens):\n",
    "\n",
    "                    if tokens[i][-3:] != \"n't\":\n",
    "                        new_line = new_line + tokens[i] + ' '\n",
    "                        i+=1\n",
    "                    \n",
    "                    else:\n",
    "                        new_line = new_line + tokens[i] + ' '\n",
    "                        try:\n",
    "                            while tokens[i+1] not in string.punctuation:\n",
    "                                new_line = new_line + 'NOT_' + tokens[i+1] + ' '\n",
    "                                i+=1\n",
    "                        except:\n",
    "                            print(\"end of sentence\")\n",
    "                        i+=1\n",
    "                new_file_sentences.append(new_line + '\\n')\n",
    "                \n",
    "            f_out.writelines(new_file_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "class PL04DataLoader_Part_1:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_labelled_dataset(self, fold = 0):\n",
    "        ''' Compile a fold of the data set\n",
    "        '''\n",
    "        dataset = []\n",
    "        for label in ('pos_negation', 'neg_negation'):\n",
    "            for document in self.get_documents(\n",
    "                fold = fold,\n",
    "                label = label,\n",
    "            ):\n",
    "                dataset.append((document, label))\n",
    "        return dataset\n",
    "    \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        ''' Enumerate the raw contents of all data set files.\n",
    "            Args:\n",
    "                data_dir: relative or absolute path to the data set folder\n",
    "                fold: which fold to load (0 to n_folds-1)\n",
    "                label: 'pos' or 'neg' to\n",
    "                    select data with positive or negative sentiment\n",
    "                    polarity\n",
    "            Return:\n",
    "                List of tokenised documents, each a list of sentences\n",
    "                that in turn are lists of tokens\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "class PL04DataLoader(PL04DataLoader_Part_1):\n",
    "    \n",
    "    def get_xval_splits(self):\n",
    "        ''' Split data with labels for cross-validation\n",
    "            returns a list of k pairs (training_data, test_data)\n",
    "            for k cross-validation\n",
    "        '''\n",
    "        # load the folds\n",
    "        folds = []\n",
    "        for i in range(10):\n",
    "            folds.append(self.get_labelled_dataset(\n",
    "                fold = i\n",
    "            ))\n",
    "        # create training-test splits\n",
    "        retval = []\n",
    "        for i in range(10):\n",
    "            test_data = folds[i]\n",
    "            training_data = []\n",
    "            for j in range(9):\n",
    "                ij1 = (i+j+1) % 10\n",
    "                assert ij1 != i\n",
    "                training_data = training_data + folds[ij1]\n",
    "            retval.append((training_data, test_data))\n",
    "        return retval\n",
    "    \n",
    "import tarfile\n",
    "import time\n",
    "\n",
    "class PL04DataLoaderFromStream(PL04DataLoader):\n",
    "        \n",
    "    def __init__(self, tgz_stream, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data = {}\n",
    "        counter = 0\n",
    "        with tarfile.open(\n",
    "            mode = 'r|gz',\n",
    "            fileobj = tgz_stream\n",
    "        ) as tar_archive:\n",
    "            for tar_member in tar_archive:\n",
    "                if counter == 2000:\n",
    "                    break\n",
    "                path_components = tar_member.name.split('/')\n",
    "                filename = path_components[-1]\n",
    "                if filename.startswith('cv') \\\n",
    "                and filename.endswith('.txt') \\\n",
    "                and '_' in filename:\n",
    "                    label = path_components[-2]\n",
    "                    fold = int(filename[2])\n",
    "                    key = (fold, label)\n",
    "                    if key not in self.data:\n",
    "                        self.data[key] = []\n",
    "                    f = tar_archive.extractfile(tar_member)\n",
    "                    document = [\n",
    "                        line.decode('utf-8').split()\n",
    "                        for line in f.readlines()\n",
    "                    ]\n",
    "                    self.data[key].append(document)\n",
    "                    counter += 1\n",
    "            \n",
    "    def get_documents(self, fold = 0, label = 'pos'):\n",
    "        return self.data[(fold, label)]\n",
    "    \n",
    "\n",
    "\n",
    "class PL04DataLoaderFromFolder(PL04DataLoader):\n",
    "    \n",
    "    def __init__(self, data_dir, **kwargs):\n",
    "        self.data_dir = data_dir\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def get_documents(self, fold = 0, label = 'pos_negation'):\n",
    "        # read folder contents\n",
    "        path = os.path.join(self.data_dir, label)\n",
    "        dir_entries = os.listdir(path)\n",
    "        # must process entries in numeric order to\n",
    "        # replicate order of original experiments\n",
    "        dir_entries.sort()\n",
    "        # check each entry and add to data if matching\n",
    "        # selection criteria\n",
    "        for filename in dir_entries:\n",
    "            if filename.startswith('cv') \\\n",
    "            and filename.endswith('.txt'):\n",
    "                if fold == int(filename[2]):\n",
    "                    # correct fold\n",
    "                    f = open(os.path.join(path, filename), 'rt')\n",
    "                    # \"yield\" tells Python to return an iterator\n",
    "                    # object that produces the yields of this\n",
    "                    # function as elements without creating a\n",
    "                    # full list of all elements\n",
    "                    yield [line.split() for line in f.readlines()]\n",
    "                    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_entries = os.listdir()\n",
    "dir_entries.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = PL04DataLoaderFromFolder(\"./data/txt_sentoken_negation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== pos_negation ==\n",
      "doc sentences start of first sentence\n",
      "  0      25   films adapted|adapted from|from comic|comic books|books have|have had\n",
      "  1      39   every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "  2      19   you've got|got mail|mail works|works alot|alot better|better than\n",
      "  3      42   \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "  4      25   moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "== neg_negation ==\n",
      "doc sentences start of first sentence\n",
      "  0      35   plot :|: two|two teen|teen couples|couples go|go to|to a|a church\n",
      "  1      13   the happy|happy bastard's|bastard's quick|quick movie|movie review\n",
      "  2      23   it is|is movies|movies like|like these|these that|that make|make a\n",
      "  3      19   \" quest|quest for|for camelot|camelot \"|\" is|is warner|warner bros\n",
      "  4      37   synopsis :|: a|a mentally|mentally unstable|unstable man|man undergoing\n"
     ]
    }
   ],
   "source": [
    "# test \"get_documents()\"\n",
    "\n",
    "def get_document_preview(document, max_length = 72):\n",
    "    s = []\n",
    "    count = 0\n",
    "    reached_limit = False\n",
    "    for sentence in document:\n",
    "        i = 0\n",
    "        while (i < len(sentence) - 1):\n",
    "            token = sentence[i] + ' ' + sentence[i+1]\n",
    "            if count + len(token) + len(s) > max_length:\n",
    "                reached_limit = True\n",
    "                break\n",
    "\n",
    "            s.append(token)\n",
    "            count += len(token)\n",
    "            i+=1\n",
    "        if reached_limit:\n",
    "            break\n",
    "    return '|'.join(s)\n",
    "    \n",
    "for label in 'pos_negation neg_negation'.split():\n",
    "    print(f'== {label} ==')\n",
    "    print('doc sentences start of first sentence')\n",
    "    for index, document in enumerate(data_loader.get_documents(\n",
    "        label = label\n",
    "    )):\n",
    "        print('%3d %7d   %s' %(\n",
    "            index, len(document), get_document_preview(document)\n",
    "        ))\n",
    "        if index == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-size te-size (number of documents)\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n",
      "   1800     200\n"
     ]
    }
   ],
   "source": [
    "# test \"get_xval_splits()\"\n",
    "\n",
    "splits = data_loader.get_xval_splits()\n",
    "\n",
    "print('tr-size te-size (number of documents)')\n",
    "for xval_tr_data, xval_te_data in splits:\n",
    "    print('%7d %7d' %(len(xval_tr_data), len(xval_te_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorInterface:\n",
    "\n",
    "    def train(self, data_with_labels):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def predict(self, data):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithVocabulary(PolarityPredictorInterface):\n",
    "    \n",
    "    def train(self, data_with_labels):\n",
    "        self.reset_vocab()\n",
    "        self.add_to_vocab_from_data(data_with_labels)\n",
    "        self.finalise_vocab()\n",
    "        tr_features = self.extract_features(\n",
    "            data_with_labels\n",
    "        )\n",
    "        tr_targets = self.get_targets(data_with_labels)\n",
    "        self.train_model_on_features(tr_features, tr_targets)\n",
    "        \n",
    "    def reset_vocab(self):\n",
    "        self.vocab = set()\n",
    "        \n",
    "    def add_to_vocab_from_data(self, data):\n",
    "        for document, label in data:\n",
    "            for sentence in document:\n",
    "                i = 0\n",
    "                while (i < len(sentence) - 1):\n",
    "                    token = sentence[i] + ' ' + sentence[i+1]\n",
    "                    self.vocab.add(token)\n",
    "                    i+=1\n",
    "\n",
    "    def finalise_vocab(self):\n",
    "        self.vocab = list(self.vocab)\n",
    "        # create reverse map for fast token lookup\n",
    "        self.token2index = {}\n",
    "        for index, token in enumerate(self.vocab):\n",
    "            self.token2index[token] = index\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_targets(self, data, label2index = None):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "class PolarityPredictorWithBagOfWords_01(PolarityPredictorWithVocabulary):\n",
    "    \n",
    "    def __init__(self, clip_counts = True):\n",
    "        self.clip_counts = clip_counts\n",
    "        \n",
    "    def extract_features(self, data):\n",
    "        # create numpy array of required size\n",
    "        columns = len(self.vocab)\n",
    "        rows = len(data)\n",
    "        features = numpy.zeros((rows, columns), dtype=numpy.int32)        \n",
    "        # populate feature matrix\n",
    "        for row, item in enumerate(data):\n",
    "            document, _ = item\n",
    "            for sentence in document:\n",
    "\n",
    "                i = 0\n",
    "                while (i < len(sentence)-1):\n",
    "                    token = sentence[i] + ' ' + sentence[i+1]\n",
    "                    i+=1\n",
    "\n",
    "                    try:\n",
    "                        index = self.token2index[token]\n",
    "                    except KeyError:\n",
    "                        # token not in vocab\n",
    "                        # --> skip this token\n",
    "                        # --> continue with next token\n",
    "                        continue\n",
    "                    if self.clip_counts:\n",
    "                        features[row, index] = 1\n",
    "                    else:\n",
    "                        features[row, index] += 1\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityPredictorWithBagOfWords(PolarityPredictorWithBagOfWords_01):\n",
    " \n",
    "    def get_targets(self, data):\n",
    "        ''' create column vector with target labels\n",
    "        '''\n",
    "        # prepare target vector\n",
    "        targets = numpy.zeros(len(data), dtype=numpy.int8)\n",
    "        index = 0\n",
    "        for _, label in data:\n",
    "            if label == 'pos_negation':\n",
    "                targets[index] = 1\n",
    "            index += 1\n",
    "        return targets\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowNB(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train NB\n",
    "        self.model = MultinomialNB()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos_negation')\n",
    "            else:\n",
    "                labels.append('neg_negation')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first functionality test\n",
    "\n",
    "model = PolarityPredictorBowNB()\n",
    "model.train(splits[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 pos_negation pos_negation films adapted|adapted from|from comic|comic books|books have|have had\n",
      "   1 pos_negation pos_negation every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "   2 pos_negation pos_negation you've got|got mail|mail works|works alot|alot better|better than\n",
      "   3 pos_negation pos_negation \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "   4 pos_negation neg_negation moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "   5 pos_negation pos_negation on june|june 30|30 ,|, 1960|1960 ,|, a|a self-taught|self-taught ,\n",
      "   6 pos_negation pos_negation apparently ,|, director|director tony|tony kaye|kaye had|had a|a major\n",
      "   7 pos_negation pos_negation one of|of my|my colleagues|colleagues was|was surprised|surprised when\n",
      "   8 pos_negation pos_negation after bloody|bloody clashes|clashes and|and independence\n",
      "   9 pos_negation pos_negation the american|american action|action film|film has|has been|been slowly\n",
      "  10 pos_negation pos_negation after watching|watching \"|\" rat|rat race|race \"|\" last|last week|week ,\n",
      "  11 pos_negation pos_negation i've noticed|noticed something|something lately|lately that|that i've\n"
     ]
    }
   ],
   "source": [
    "def print_first_predictions(model, te_data, n = 12):\n",
    "    predictions = model.predict(te_data)\n",
    "    for i in range(n):\n",
    "        document, label = te_data[i]\n",
    "        prediction = predictions[i]\n",
    "        print('%4d %s %s %s' %(\n",
    "            i, label, prediction,\n",
    "            get_document_preview(document),\n",
    "        ))\n",
    "    \n",
    "print_first_predictions(model, splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "[[77 23]\n",
      " [13 87]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.82\n",
      "Precision --> 0.77\n",
      "Recall --> 0.8555555555555555\n",
      "F1 --> 0.8105263157894737\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.88\n",
      "Precision --> 0.86\n",
      "Recall --> 0.8958333333333334\n",
      "F1 --> 0.8775510204081632\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.82\n",
      "Recall --> 0.8541666666666666\n",
      "F1 --> 0.836734693877551\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.88\n",
      "Precision --> 0.82\n",
      "Recall --> 0.9318181818181818\n",
      "F1 --> 0.8723404255319149\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.81\n",
      "Precision --> 0.77\n",
      "Recall --> 0.8369565217391305\n",
      "F1 --> 0.8020833333333334\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.84\n",
      "Precision --> 0.77\n",
      "Recall --> 0.8953488372093024\n",
      "F1 --> 0.8279569892473118\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.875\n",
      "Precision --> 0.82\n",
      "Recall --> 0.9213483146067416\n",
      "F1 --> 0.8677248677248677\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.86\n",
      "Precision --> 0.8\n",
      "Recall --> 0.9090909090909091\n",
      "F1 --> 0.8510638297872342\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.845\n",
      "Precision --> 0.81\n",
      "Recall --> 0.8709677419354839\n",
      "F1 --> 0.8393782383419689\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.855\n",
      "Precision --> 0.82\n",
      "Recall --> 0.8817204301075269\n",
      "F1 --> 0.849740932642487\n",
      "\n",
      "(0.8435100646684306, 0.02400227480759943, 0.8020833333333334, 0.8775510204081632)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, splits, verbose = False):\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    fold = 0\n",
    "    for tr_data, te_data in splits:\n",
    "        if verbose:\n",
    "            print('Evaluating fold %d of %d' %(fold+1, len(splits)))\n",
    "            fold += 1\n",
    "        model.train(tr_data)\n",
    "        _, accuracy, confusion_matrix = model.predict(te_data, get_accuracy = True, get_confusion_matrix = True)\n",
    "       \n",
    "        tp, fp, fn, tn = confusion_matrix[0][0], confusion_matrix[0][1], confusion_matrix[1][0], confusion_matrix[1][1]\n",
    "        prec = tp/(tp + fp)\n",
    "        rec = tp/(tp + fn)\n",
    "        f1 = (2*prec*rec)/(prec+rec)\n",
    "       \n",
    "        accuracies.append(accuracy)\n",
    "        f1s.append(f1)\n",
    "        if verbose:\n",
    "            print('Accuracy -->', accuracy)\n",
    "            print('Precision -->', prec)\n",
    "            print('Recall -->', rec)\n",
    "            print('F1 -->', f1)\n",
    "            print()\n",
    "    n = float(len(accuracies))\n",
    "    avg = sum(f1s) / n\n",
    "    mse = sum([(x-avg)**2 for x in accuracies]) / n\n",
    "    return (avg, mse**0.5, min(f1s),\n",
    "            max(f1s))\n",
    "\n",
    "# this takes about 3 minutes\n",
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "class PolarityPredictorBowLR(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowLR()\n",
    "model.train(splits[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 pos_negation pos films adapted|adapted from|from comic|comic books|books have|have had\n",
      "   1 pos_negation pos every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "   2 pos_negation neg you've got|got mail|mail works|works alot|alot better|better than\n",
      "   3 pos_negation pos \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "   4 pos_negation neg moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "   5 pos_negation pos on june|june 30|30 ,|, 1960|1960 ,|, a|a self-taught|self-taught ,\n",
      "   6 pos_negation pos apparently ,|, director|director tony|tony kaye|kaye had|had a|a major\n",
      "   7 pos_negation pos one of|of my|my colleagues|colleagues was|was surprised|surprised when\n",
      "   8 pos_negation pos after bloody|bloody clashes|clashes and|and independence\n",
      "   9 pos_negation pos the american|american action|action film|film has|has been|been slowly\n",
      "  10 pos_negation pos after watching|watching \"|\" rat|rat race|race \"|\" last|last week|week ,\n",
      "  11 pos_negation pos i've noticed|noticed something|something lately|lately that|that i've\n"
     ]
    }
   ],
   "source": [
    "print_first_predictions(model, splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835\n",
      "[[87 13]\n",
      " [20 80]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.835\n",
      "Precision --> 0.87\n",
      "Recall --> 0.8130841121495327\n",
      "F1 --> 0.8405797101449274\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.86\n",
      "Precision --> 0.89\n",
      "Recall --> 0.839622641509434\n",
      "F1 --> 0.8640776699029127\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.81\n",
      "Precision --> 0.91\n",
      "Recall --> 0.7583333333333333\n",
      "F1 --> 0.8272727272727273\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.825\n",
      "Precision --> 0.84\n",
      "Recall --> 0.8155339805825242\n",
      "F1 --> 0.8275862068965517\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.79\n",
      "Precision --> 0.8\n",
      "Recall --> 0.7843137254901961\n",
      "F1 --> 0.792079207920792\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.82\n",
      "Precision --> 0.88\n",
      "Recall --> 0.7857142857142857\n",
      "F1 --> 0.830188679245283\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.83\n",
      "Precision --> 0.8\n",
      "Recall --> 0.851063829787234\n",
      "F1 --> 0.8247422680412372\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.82\n",
      "Precision --> 0.81\n",
      "Recall --> 0.826530612244898\n",
      "F1 --> 0.8181818181818183\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.835\n",
      "Precision --> 0.88\n",
      "Recall --> 0.8073394495412844\n",
      "F1 --> 0.8421052631578948\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.835\n",
      "Precision --> 0.85\n",
      "Recall --> 0.8252427184466019\n",
      "F1 --> 0.8374384236453202\n",
      "\n",
      "(0.8304251974409464, 0.017988395492410058, 0.792079207920792, 0.8640776699029127)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class PolarityPredictorBowDT(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = DecisionTreeClassifier()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowDT()\n",
    "model.train(splits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585\n",
      "[[54 46]\n",
      " [37 63]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.62\n",
      "Precision --> 0.56\n",
      "Recall --> 0.6363636363636364\n",
      "F1 --> 0.5957446808510639\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.565\n",
      "Precision --> 0.49\n",
      "Recall --> 0.5764705882352941\n",
      "F1 --> 0.5297297297297296\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.645\n",
      "Precision --> 0.69\n",
      "Recall --> 0.6330275229357798\n",
      "F1 --> 0.6602870813397128\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.615\n",
      "Precision --> 0.59\n",
      "Recall --> 0.6210526315789474\n",
      "F1 --> 0.6051282051282052\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.59\n",
      "Precision --> 0.57\n",
      "Recall --> 0.59375\n",
      "F1 --> 0.5816326530612245\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.64\n",
      "Precision --> 0.68\n",
      "Recall --> 0.6296296296296297\n",
      "F1 --> 0.6538461538461539\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.595\n",
      "Precision --> 0.59\n",
      "Recall --> 0.5959595959595959\n",
      "F1 --> 0.5929648241206029\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.61\n",
      "Precision --> 0.64\n",
      "Recall --> 0.6037735849056604\n",
      "F1 --> 0.6213592233009708\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.6\n",
      "Precision --> 0.63\n",
      "Recall --> 0.5943396226415094\n",
      "F1 --> 0.6116504854368932\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.635\n",
      "Precision --> 0.59\n",
      "Recall --> 0.6483516483516484\n",
      "F1 --> 0.6178010471204188\n",
      "\n",
      "(0.6070144083934975, 0.02409088068253891, 0.5297297297297296, 0.6602870813397128)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class PolarityPredictorBowSVM(PolarityPredictorWithBagOfWords):\n",
    "\n",
    "    def train_model_on_features(self, tr_features, tr_targets):\n",
    "        # pass numpy array to sklearn to train Logistic Regression\n",
    "        # iterations set to 1000 as default of 100 didn't guarantee convergence with our data\n",
    "        self.model = svm.SVC()\n",
    "        self.model.fit(tr_features, tr_targets)\n",
    "        \n",
    "    def predict(\n",
    "        self, data, get_accuracy = False,\n",
    "        get_confusion_matrix = False\n",
    "    ):\n",
    "        features = self.extract_features(data)\n",
    "        # use numpy to get predictions\n",
    "        y_pred = self.model.predict(features)\n",
    "        # restore labels\n",
    "        labels = []\n",
    "        for is_positive in y_pred:\n",
    "            if is_positive:\n",
    "                labels.append('pos')\n",
    "            else:\n",
    "                labels.append('neg')\n",
    "        if get_accuracy or get_confusion_matrix:\n",
    "            retval = []\n",
    "            retval.append(labels)\n",
    "            y_true = self.get_targets(data)\n",
    "            if get_accuracy:\n",
    "                retval.append(\n",
    "                    metrics.accuracy_score(y_true, y_pred)\n",
    "                )\n",
    "            if get_confusion_matrix:\n",
    "                retval.append(\n",
    "                    metrics.confusion_matrix(y_true, y_pred)\n",
    "                )\n",
    "            return retval\n",
    "        else:\n",
    "            return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolarityPredictorBowSVM()\n",
    "model.train(splits[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 pos_negation neg films adapted|adapted from|from comic|comic books|books have|have had\n",
      "   1 pos_negation neg every now|now and|and then|then a|a movie|movie comes|comes along\n",
      "   2 pos_negation neg you've got|got mail|mail works|works alot|alot better|better than\n",
      "   3 pos_negation pos \" jaws|jaws \"|\" is|is a|a rare|rare film|film that|that grabs|grabs your\n",
      "   4 pos_negation neg moviemaking is|is a|a lot|lot like|like being|being the|the general\n",
      "   5 pos_negation pos on june|june 30|30 ,|, 1960|1960 ,|, a|a self-taught|self-taught ,\n",
      "   6 pos_negation pos apparently ,|, director|director tony|tony kaye|kaye had|had a|a major\n",
      "   7 pos_negation pos one of|of my|my colleagues|colleagues was|was surprised|surprised when\n",
      "   8 pos_negation neg after bloody|bloody clashes|clashes and|and independence\n",
      "   9 pos_negation pos the american|american action|action film|film has|has been|been slowly\n",
      "  10 pos_negation pos after watching|watching \"|\" rat|rat race|race \"|\" last|last week|week ,\n",
      "  11 pos_negation neg i've noticed|noticed something|something lately|lately that|that i've\n"
     ]
    }
   ],
   "source": [
    "print_first_predictions(model, splits[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n",
      "[[96  4]\n",
      " [50 50]]\n"
     ]
    }
   ],
   "source": [
    "labels, accuracy, confusion_matrix = model.predict(\n",
    "    splits[0][1], get_accuracy = True, get_confusion_matrix = True\n",
    ")\n",
    "\n",
    "print(accuracy)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1 of 10\n",
      "Accuracy --> 0.73\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6575342465753424\n",
      "F1 --> 0.7804878048780488\n",
      "\n",
      "Evaluating fold 2 of 10\n",
      "Accuracy --> 0.765\n",
      "Precision --> 0.98\n",
      "Recall --> 0.6853146853146853\n",
      "F1 --> 0.8065843621399176\n",
      "\n",
      "Evaluating fold 3 of 10\n",
      "Accuracy --> 0.69\n",
      "Precision --> 0.95\n",
      "Recall --> 0.625\n",
      "F1 --> 0.753968253968254\n",
      "\n",
      "Evaluating fold 4 of 10\n",
      "Accuracy --> 0.705\n",
      "Precision --> 0.94\n",
      "Recall --> 0.6394557823129252\n",
      "F1 --> 0.7611336032388665\n",
      "\n",
      "Evaluating fold 5 of 10\n",
      "Accuracy --> 0.685\n",
      "Precision --> 0.95\n",
      "Recall --> 0.6209150326797386\n",
      "F1 --> 0.7509881422924901\n",
      "\n",
      "Evaluating fold 6 of 10\n",
      "Accuracy --> 0.725\n",
      "Precision --> 0.93\n",
      "Recall --> 0.6595744680851063\n",
      "F1 --> 0.7717842323651452\n",
      "\n",
      "Evaluating fold 7 of 10\n",
      "Accuracy --> 0.745\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6713286713286714\n",
      "F1 --> 0.7901234567901235\n",
      "\n",
      "Evaluating fold 8 of 10\n",
      "Accuracy --> 0.73\n",
      "Precision --> 0.94\n",
      "Recall --> 0.6619718309859155\n",
      "F1 --> 0.7768595041322315\n",
      "\n",
      "Evaluating fold 9 of 10\n",
      "Accuracy --> 0.76\n",
      "Precision --> 0.96\n",
      "Recall --> 0.6857142857142857\n",
      "F1 --> 0.7999999999999999\n",
      "\n",
      "Evaluating fold 10 of 10\n",
      "Accuracy --> 0.735\n",
      "Precision --> 0.95\n",
      "Recall --> 0.6643356643356644\n",
      "F1 --> 0.7818930041152263\n",
      "\n",
      "(0.7773822363920303, 0.05651875568218415, 0.7509881422924901, 0.8065843621399176)\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, splits, verbose = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This combination of negation handling and bigram usage seemed to be ultimately mediocre at best.\n",
    "\n",
    "The only algorithm that beat the baseline was the Naive Bayes version and only marginally. Considering the large time cost of running this, particularly for SVM and Decision Tree, it may be best to avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
